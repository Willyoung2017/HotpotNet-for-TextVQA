@InProceedings{Singh_2019_CVPR,
author = {Singh, Amanpreet and Natarajan, Vivek and Shah, Meet and Jiang, Yu and Chen, Xinlei and Batra, Dhruv and Parikh, Devi and Rohrbach, Marcus},
title = {Towards VQA Models That Can Read},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2019}
}

@InProceedings{qiao2021winner,
      title={Winner Team Mia at TextVQA Challenge 2021: Vision-and-Language Representation Learning with Pre-trained Sequence-to-Sequence Model}, 
      author={Yixuan Qiao and Hao Chen and Jun Wang and Yihao Chen and Xianbin Ye and Ziliang Li and Xianbiao Qi and Peng Gao and Guotong Xie},
      year={2021},
      eprint={2106.15332},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{xu2020layoutlm,
  title={Layoutlm: Pre-training of text and layout for document image understanding},
  author={Xu, Yiheng and Li, Minghao and Cui, Lei and Huang, Shaohan and Wei, Furu and Zhou, Ming},
  booktitle={Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={1192--1200},
  year={2020}
}

@inproceedings{hu2020iterative,
  title={Iterative answer prediction with pointer-augmented multimodal transformers for textvqa},
  author={Hu, Ronghang and Singh, Amanpreet and Darrell, Trevor and Rohrbach, Marcus},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9992--10002},
  year={2020}
}

@inproceedings{xu2021layoutlmv2,
  title={LayoutLMv2: Multi-modal Pre-training for Visually-rich Document Understanding},
  author={Xu, Yang and Xu, Yiheng and Lv, Tengchao and Cui, Lei and Wei, Furu and Wang, Guoxin and Lu, Yijuan and Florencio, Dinei and Zhang, Cha and Che, Wanxiang and others},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={2579--2591},
  year={2021}
}

@inproceedings{kant2020spatially,
  title={Spatially aware multimodal transformers for textvqa},
  author={Kant, Yash and Batra, Dhruv and Anderson, Peter and Schwing, Alexander and Parikh, Devi and Lu, Jiasen and Agrawal, Harsh},
  booktitle={European Conference on Computer Vision},
  pages={715--732},
  year={2020},
  organization={Springer}
}

@inproceedings{sidorov2020textcaps,
      title={TextCaps: a Dataset for Image Captioning with Reading Comprehension}, 
      author={Oleksii Sidorov and Ronghang Hu and Marcus Rohrbach and Amanpreet Singh},
      year={2020},
      eprint={2003.12462},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@inproceedings{mathew2021docvqa,
  title={Docvqa: A dataset for vqa on document images},
  author={Mathew, Minesh and Karatzas, Dimosthenis and Jawahar, CV},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={2200--2209},
  year={2021}
}