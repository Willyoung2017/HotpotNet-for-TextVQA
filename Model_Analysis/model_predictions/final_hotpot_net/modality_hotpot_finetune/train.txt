2022-05-06T14:54:49 | INFO | mmf : Logging to: ./save/hotpot_modality_finetune/train.log
2022-05-06T14:54:49 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['dataset=modality_hotpot', 'model=hotpot_net', 'config=projects/my_textvqa/configs/hotpot_net/mask_finetune.yaml', 'env.save_dir=./save/hotpot_modality_finetune', 'training.batch_size=129', 'training.num_workers=4', 'training.update_frequency=1'])
2022-05-06T14:54:49 | INFO | mmf_cli.run : Torch version: 1.9.0+cu111
2022-05-06T14:54:49 | INFO | mmf.utils.general : CUDA Device 0 is: NVIDIA RTX A6000
2022-05-06T14:54:49 | INFO | mmf_cli.run : Using seed 51040596
2022-05-06T14:54:49 | INFO | mmf_cli.run : Building trainer
2022-05-06T14:54:49 | INFO | mmf_cli.run : Loading trainer
2022-05-06T14:54:49 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2022-05-06T14:54:52 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-06T14:54:52 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-06T14:54:52 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-06T14:54:52 | INFO | mmf.trainers.mmf_trainer : Loading model
2022-05-06T14:54:52 | INFO | mmf.trainers.mmf_trainer : hotpot_net, {'hotpot_net': {'pretrain': False, 'do_mask_finetuning': False, 'use_lorra': False, 'use_mmt': True, 'use_question': True, 'use_ocr': True, 'use_object': True, 'use_whole_img': False, 'whole_img_model': 'vit', 'whole_img_model_layer': 5, 'lr_scale_frcn': 0.1, 'lr_scale_text_bert': 0.1, 'lr_scale_mmt': 1.0, 'text_bert_init_from_bert_base': True, 'text_bert': {'num_hidden_layers': 3}, 'obj': {'mmt_in_dim': 2816, 'dropout_prob': 0.1}, 'ocr': {'mmt_in_dim': 3420, 'dropout_prob': 0.1}, 'whole_img': {'mmt_in_dim': 768}, 'mmt': {'hidden_size': 768, 'num_hidden_layers': 4}, 'classifier': {'type': 'linear', 'ocr_max_num': 100, 'ocr_ptr_net': {'hidden_size': 768, 'query_key_size': 768}, 'params': {}}, 'model_data_dir': './cache/data', 'losses': [{'type': 'm4c_decoding_bce_with_mask'}]}}
2022-05-06T14:54:52 | INFO | mmf.trainers.mmf_trainer : Building model
2022-05-06T14:54:56 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2022-05-06T14:54:56 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2022-05-06T14:54:56 | WARNING | py.warnings : /usr1/data/yuweiwu/mmf/mmf/utils/build.py:474: UserWarning: No type for scheduler specified even though lr_scheduler is True, setting default to 'Pythia'
  "No type for scheduler specified even though lr_scheduler is True, "

2022-05-06T14:54:56 | WARNING | py.warnings : /usr1/data/yuweiwu/mmf/mmf/utils/build.py:474: UserWarning: No type for scheduler specified even though lr_scheduler is True, setting default to 'Pythia'
  "No type for scheduler specified even though lr_scheduler is True, "

2022-05-06T14:54:56 | WARNING | py.warnings : /usr1/data/yuweiwu/mmf/mmf/utils/build.py:480: UserWarning: scheduler attributes has no params defined, defaulting to {}.
  warnings.warn("scheduler attributes has no params defined, defaulting to {}.")

2022-05-06T14:54:56 | WARNING | py.warnings : /usr1/data/yuweiwu/mmf/mmf/utils/build.py:480: UserWarning: scheduler attributes has no params defined, defaulting to {}.
  warnings.warn("scheduler attributes has no params defined, defaulting to {}.")

2022-05-06T14:54:56 | INFO | mmf_cli.run : === Start Training ===
2022-05-06T14:54:56 | INFO | mmf.trainers.core.training_loop : Starting training...
2022-05-06T14:56:24 | INFO | mmf.trainers.callbacks.logistics : progress: 100/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 720.8040, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 720.8040, train/total_loss: 720.8040, train/total_loss/avg: 720.8040, max mem: 19998.0, experiment: run, epoch: 1, num_updates: 100, iterations: 100, max_updates: 24000, lr: 0.00003, ups: 1.14, time: 01m 28s 206ms, time_since_start: 01m 28s 208ms, eta: 06h 05m 03s 582ms
2022-05-06T14:57:46 | INFO | mmf.trainers.callbacks.logistics : progress: 200/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 68.2912, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 394.5476, train/total_loss: 68.2912, train/total_loss/avg: 394.5476, max mem: 19998.0, experiment: run, epoch: 1, num_updates: 200, iterations: 200, max_updates: 24000, lr: 0.00004, ups: 1.23, time: 01m 21s 603ms, time_since_start: 02m 49s 812ms, eta: 05h 36m 18s 996ms
2022-05-06T14:59:12 | INFO | mmf.trainers.callbacks.logistics : progress: 300/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 68.2912, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 267.4891, train/total_loss: 68.2912, train/total_loss/avg: 267.4891, max mem: 19998.0, experiment: run, epoch: 2, num_updates: 300, iterations: 300, max_updates: 24000, lr: 0.00004, ups: 1.16, time: 01m 26s 016ms, time_since_start: 04m 15s 828ms, eta: 05h 53m 891ms
2022-05-06T15:00:35 | INFO | mmf.trainers.callbacks.logistics : progress: 400/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 13.3719, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 202.5471, train/total_loss: 13.3719, train/total_loss/avg: 202.5471, max mem: 19998.0, experiment: run, epoch: 2, num_updates: 400, iterations: 400, max_updates: 24000, lr: 0.00005, ups: 1.20, time: 01m 23s 575ms, time_since_start: 05m 39s 404ms, eta: 05h 41m 33s 168ms
2022-05-06T15:02:06 | INFO | mmf.trainers.callbacks.logistics : progress: 500/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 13.3719, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 163.4446, train/total_loss: 13.3719, train/total_loss/avg: 163.4446, max mem: 19998.0, experiment: run, epoch: 2, num_updates: 500, iterations: 500, max_updates: 24000, lr: 0.00006, ups: 1.11, time: 01m 30s 943ms, time_since_start: 07m 10s 347ms, eta: 06h 10m 05s 127ms
2022-05-06T15:03:40 | INFO | mmf.trainers.callbacks.logistics : progress: 600/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 7.7211, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 137.3160, train/total_loss: 7.7211, train/total_loss/avg: 137.3160, max mem: 19998.0, experiment: run, epoch: 3, num_updates: 600, iterations: 600, max_updates: 24000, lr: 0.00007, ups: 1.08, time: 01m 33s 576ms, time_since_start: 08m 43s 924ms, eta: 06h 19m 10s 870ms
2022-05-06T15:05:10 | INFO | mmf.trainers.callbacks.logistics : progress: 700/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 7.7211, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 118.6250, train/total_loss: 7.7211, train/total_loss/avg: 118.6250, max mem: 19998.0, experiment: run, epoch: 3, num_updates: 700, iterations: 700, max_updates: 24000, lr: 0.00008, ups: 1.11, time: 01m 30s 018ms, time_since_start: 10m 13s 942ms, eta: 06h 03m 12s 303ms
2022-05-06T15:06:41 | INFO | mmf.trainers.callbacks.logistics : progress: 800/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 7.0350, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 104.6417, train/total_loss: 7.0350, train/total_loss/avg: 104.6417, max mem: 19998.0, experiment: run, epoch: 3, num_updates: 800, iterations: 800, max_updates: 24000, lr: 0.00008, ups: 1.10, time: 01m 31s 597ms, time_since_start: 11m 45s 539ms, eta: 06h 07m 59s 359ms
2022-05-06T15:08:13 | INFO | mmf.trainers.callbacks.logistics : progress: 900/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 7.0350, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 93.6299, train/total_loss: 7.0350, train/total_loss/avg: 93.6299, max mem: 19998.0, experiment: run, epoch: 4, num_updates: 900, iterations: 900, max_updates: 24000, lr: 0.00009, ups: 1.10, time: 01m 31s 686ms, time_since_start: 13m 17s 226ms, eta: 06h 06m 45s 628ms
2022-05-06T15:09:46 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-06T15:09:46 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T15:09:47 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T15:09:48 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T15:09:48 | INFO | mmf.trainers.callbacks.logistics : progress: 1000/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 6.7586, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 84.8823, train/total_loss: 6.7586, train/total_loss/avg: 84.8823, max mem: 19998.0, experiment: run, epoch: 4, num_updates: 1000, iterations: 1000, max_updates: 24000, lr: 0.0001, ups: 1.05, time: 01m 35s 349ms, time_since_start: 14m 52s 575ms, eta: 06h 19m 45s 582ms
2022-05-06T15:09:48 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-06T15:09:48 | INFO | mmf.common.test_reporter : Predicting for modality_hotpot
2022-05-06T15:11:07 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 39
2022-05-06T15:11:07 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-06T15:11:09 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T15:11:14 | INFO | mmf.utils.checkpoint : Saving best checkpoint
2022-05-06T15:11:15 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T15:11:20 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T15:11:20 | INFO | mmf.trainers.callbacks.logistics : progress: 1000/24000, val/modality_hotpot/m4c_decoding_bce_with_mask: 6.2521, val/total_loss: 6.2521, val/modality_hotpot/textvqa_accuracy: 0.3610, num_updates: 1000, epoch: 4, iterations: 1000, max_updates: 24000, val_time: 01m 31s 681ms, best_update: 1000, best_iteration: 1000, best_val/modality_hotpot/textvqa_accuracy: 0.361020
2022-05-06T15:12:57 | INFO | mmf.trainers.callbacks.logistics : progress: 1100/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 6.7586, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 77.7043, train/total_loss: 6.7586, train/total_loss/avg: 77.7043, max mem: 20582.0, experiment: run, epoch: 5, num_updates: 1100, iterations: 1100, max_updates: 24000, lr: 0.0001, ups: 1.03, time: 01m 37s 428ms, time_since_start: 18m 01s 686ms, eta: 06h 26m 21s 241ms
2022-05-06T15:14:34 | INFO | mmf.trainers.callbacks.logistics : progress: 1200/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 6.6726, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 71.6840, train/total_loss: 6.6726, train/total_loss/avg: 71.6840, max mem: 20582.0, experiment: run, epoch: 5, num_updates: 1200, iterations: 1200, max_updates: 24000, lr: 0.0001, ups: 1.04, time: 01m 36s 754ms, time_since_start: 19m 38s 441ms, eta: 06h 22m 486ms
2022-05-06T15:16:08 | INFO | mmf.trainers.callbacks.logistics : progress: 1300/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 6.6726, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 66.6140, train/total_loss: 6.6726, train/total_loss/avg: 66.6140, max mem: 20582.0, experiment: run, epoch: 5, num_updates: 1300, iterations: 1300, max_updates: 24000, lr: 0.0001, ups: 1.08, time: 01m 33s 520ms, time_since_start: 21m 11s 961ms, eta: 06h 07m 36s 999ms
2022-05-06T15:17:39 | INFO | mmf.trainers.callbacks.logistics : progress: 1400/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 6.4792, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 62.2242, train/total_loss: 6.4792, train/total_loss/avg: 62.2242, max mem: 20582.0, experiment: run, epoch: 6, num_updates: 1400, iterations: 1400, max_updates: 24000, lr: 0.0001, ups: 1.10, time: 01m 31s 343ms, time_since_start: 22m 43s 304ms, eta: 05h 57m 28s 686ms
2022-05-06T15:19:06 | INFO | mmf.trainers.callbacks.logistics : progress: 1500/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 6.4792, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 58.3962, train/total_loss: 6.4792, train/total_loss/avg: 58.3962, max mem: 20582.0, experiment: run, epoch: 6, num_updates: 1500, iterations: 1500, max_updates: 24000, lr: 0.0001, ups: 1.16, time: 01m 26s 637ms, time_since_start: 24m 09s 941ms, eta: 05h 37m 33s 605ms
2022-05-06T15:20:48 | INFO | mmf.trainers.callbacks.logistics : progress: 1600/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 6.1545, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 55.0771, train/total_loss: 6.1545, train/total_loss/avg: 55.0771, max mem: 20582.0, experiment: run, epoch: 6, num_updates: 1600, iterations: 1600, max_updates: 24000, lr: 0.0001, ups: 0.98, time: 01m 42s 447ms, time_since_start: 25m 52s 389ms, eta: 06h 37m 23s 215ms
2022-05-06T15:22:31 | INFO | mmf.trainers.callbacks.logistics : progress: 1700/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 6.1545, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 52.1343, train/total_loss: 6.1545, train/total_loss/avg: 52.1343, max mem: 20582.0, experiment: run, epoch: 7, num_updates: 1700, iterations: 1700, max_updates: 24000, lr: 0.0001, ups: 0.98, time: 01m 42s 722ms, time_since_start: 27m 35s 111ms, eta: 06h 36m 40s 455ms
2022-05-06T15:24:11 | INFO | mmf.trainers.callbacks.logistics : progress: 1800/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 5.9238, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 49.4995, train/total_loss: 5.9238, train/total_loss/avg: 49.4995, max mem: 20582.0, experiment: run, epoch: 7, num_updates: 1800, iterations: 1800, max_updates: 24000, lr: 0.0001, ups: 1.00, time: 01m 40s 028ms, time_since_start: 29m 15s 139ms, eta: 06h 24m 32s 313ms
2022-05-06T15:25:48 | INFO | mmf.trainers.callbacks.logistics : progress: 1900/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 5.9238, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 47.1378, train/total_loss: 5.9238, train/total_loss/avg: 47.1378, max mem: 20582.0, experiment: run, epoch: 8, num_updates: 1900, iterations: 1900, max_updates: 24000, lr: 0.0001, ups: 1.03, time: 01m 37s 423ms, time_since_start: 30m 52s 563ms, eta: 06h 12m 50s 306ms
2022-05-06T15:27:26 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-06T15:27:26 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T15:27:28 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T15:27:32 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T15:27:33 | INFO | mmf.trainers.callbacks.logistics : progress: 2000/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 5.7746, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 45.0245, train/total_loss: 5.7746, train/total_loss/avg: 45.0245, max mem: 20582.0, experiment: run, epoch: 8, num_updates: 2000, iterations: 2000, max_updates: 24000, lr: 0.0001, ups: 0.96, time: 01m 44s 136ms, time_since_start: 32m 36s 699ms, eta: 06h 36m 43s 482ms
2022-05-06T15:27:33 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-06T15:27:33 | INFO | mmf.common.test_reporter : Predicting for modality_hotpot
2022-05-06T15:28:24 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 39
2022-05-06T15:28:24 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-06T15:28:26 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T15:28:31 | INFO | mmf.utils.checkpoint : Saving best checkpoint
2022-05-06T15:28:36 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T15:28:40 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T15:28:40 | INFO | mmf.trainers.callbacks.logistics : progress: 2000/24000, val/modality_hotpot/m4c_decoding_bce_with_mask: 5.6888, val/total_loss: 5.6888, val/modality_hotpot/textvqa_accuracy: 0.4286, num_updates: 2000, epoch: 8, iterations: 2000, max_updates: 24000, val_time: 01m 07s 877ms, best_update: 2000, best_iteration: 2000, best_val/modality_hotpot/textvqa_accuracy: 0.428600
2022-05-06T15:30:12 | INFO | mmf.trainers.callbacks.logistics : progress: 2100/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 5.5353, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 43.1028, train/total_loss: 5.5353, train/total_loss/avg: 43.1028, max mem: 20583.0, experiment: run, epoch: 8, num_updates: 2100, iterations: 2100, max_updates: 24000, lr: 0.0001, ups: 1.10, time: 01m 31s 768ms, time_since_start: 35m 16s 346ms, eta: 05h 48m 01s 092ms
2022-05-06T15:31:47 | INFO | mmf.trainers.callbacks.logistics : progress: 2200/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 5.4603, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 41.3222, train/total_loss: 5.4603, train/total_loss/avg: 41.3222, max mem: 20583.0, experiment: run, epoch: 9, num_updates: 2200, iterations: 2200, max_updates: 24000, lr: 0.0001, ups: 1.06, time: 01m 34s 388ms, time_since_start: 36m 50s 735ms, eta: 05h 56m 19s 255ms
2022-05-06T15:33:18 | INFO | mmf.trainers.callbacks.logistics : progress: 2300/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 5.2913, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 39.7250, train/total_loss: 5.2913, train/total_loss/avg: 39.7250, max mem: 20583.0, experiment: run, epoch: 9, num_updates: 2300, iterations: 2300, max_updates: 24000, lr: 0.0001, ups: 1.10, time: 01m 31s 738ms, time_since_start: 38m 22s 474ms, eta: 05h 44m 43s 612ms
2022-05-06T15:34:52 | INFO | mmf.trainers.callbacks.logistics : progress: 2400/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 5.1560, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 38.2563, train/total_loss: 5.1560, train/total_loss/avg: 38.2563, max mem: 20583.0, experiment: run, epoch: 9, num_updates: 2400, iterations: 2400, max_updates: 24000, lr: 0.0001, ups: 1.08, time: 01m 33s 475ms, time_since_start: 39m 55s 949ms, eta: 05h 49m 38s 175ms
2022-05-06T15:36:28 | INFO | mmf.trainers.callbacks.logistics : progress: 2500/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 5.0485, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 36.8992, train/total_loss: 5.0485, train/total_loss/avg: 36.8992, max mem: 20583.0, experiment: run, epoch: 10, num_updates: 2500, iterations: 2500, max_updates: 24000, lr: 0.0001, ups: 1.04, time: 01m 36s 525ms, time_since_start: 41m 32s 475ms, eta: 05h 59m 22s 449ms
2022-05-06T15:38:01 | INFO | mmf.trainers.callbacks.logistics : progress: 2600/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 4.8735, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 35.6367, train/total_loss: 4.8735, train/total_loss/avg: 35.6367, max mem: 20583.0, experiment: run, epoch: 10, num_updates: 2600, iterations: 2600, max_updates: 24000, lr: 0.0001, ups: 1.09, time: 01m 32s 843ms, time_since_start: 43m 05s 319ms, eta: 05h 44m 03s 472ms
2022-05-06T15:39:47 | INFO | mmf.trainers.callbacks.logistics : progress: 2700/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 4.8044, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 34.4554, train/total_loss: 4.8044, train/total_loss/avg: 34.4554, max mem: 20583.0, experiment: run, epoch: 11, num_updates: 2700, iterations: 2700, max_updates: 24000, lr: 0.0001, ups: 0.95, time: 01m 45s 861ms, time_since_start: 44m 51s 181ms, eta: 06h 30m 27s 937ms
2022-05-06T15:41:20 | INFO | mmf.trainers.callbacks.logistics : progress: 2800/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 4.7078, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 33.3661, train/total_loss: 4.7078, train/total_loss/avg: 33.3661, max mem: 20583.0, experiment: run, epoch: 11, num_updates: 2800, iterations: 2800, max_updates: 24000, lr: 0.0001, ups: 1.09, time: 01m 32s 686ms, time_since_start: 46m 23s 867ms, eta: 05h 40m 15s 827ms
2022-05-06T15:42:58 | INFO | mmf.trainers.callbacks.logistics : progress: 2900/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 4.6673, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 32.3461, train/total_loss: 4.6673, train/total_loss/avg: 32.3461, max mem: 20583.0, experiment: run, epoch: 11, num_updates: 2900, iterations: 2900, max_updates: 24000, lr: 0.0001, ups: 1.02, time: 01m 38s 337ms, time_since_start: 48m 02s 205ms, eta: 05h 59m 18s 461ms
2022-05-06T15:44:47 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-06T15:44:47 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T15:44:48 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T15:44:53 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T15:44:53 | INFO | mmf.trainers.callbacks.logistics : progress: 3000/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 4.6270, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 31.3932, train/total_loss: 4.6270, train/total_loss/avg: 31.3932, max mem: 20583.0, experiment: run, epoch: 12, num_updates: 3000, iterations: 3000, max_updates: 24000, lr: 0.0001, ups: 0.87, time: 01m 55s 015ms, time_since_start: 49m 57s 221ms, eta: 06h 58m 15s 310ms
2022-05-06T15:44:53 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-06T15:44:53 | INFO | mmf.common.test_reporter : Predicting for modality_hotpot
2022-05-06T15:46:06 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 39
2022-05-06T15:46:06 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-06T15:46:08 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T15:46:12 | INFO | mmf.utils.checkpoint : Saving best checkpoint
2022-05-06T15:46:17 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T15:46:21 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T15:46:21 | INFO | mmf.trainers.callbacks.logistics : progress: 3000/24000, val/modality_hotpot/m4c_decoding_bce_with_mask: 5.6236, val/total_loss: 5.6236, val/modality_hotpot/textvqa_accuracy: 0.4507, num_updates: 3000, epoch: 12, iterations: 3000, max_updates: 24000, val_time: 01m 28s 187ms, best_update: 3000, best_iteration: 3000, best_val/modality_hotpot/textvqa_accuracy: 0.450660
2022-05-06T15:48:22 | INFO | mmf.trainers.callbacks.logistics : progress: 3100/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 4.5875, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 30.4950, train/total_loss: 4.5875, train/total_loss/avg: 30.4950, max mem: 20584.0, experiment: run, epoch: 12, num_updates: 3100, iterations: 3100, max_updates: 24000, lr: 0.0001, ups: 0.83, time: 02m 01s 144ms, time_since_start: 53m 26s 557ms, eta: 07h 18m 26s 582ms
2022-05-06T15:50:22 | INFO | mmf.trainers.callbacks.logistics : progress: 3200/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 4.4765, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 29.6589, train/total_loss: 4.4765, train/total_loss/avg: 29.6589, max mem: 20584.0, experiment: run, epoch: 12, num_updates: 3200, iterations: 3200, max_updates: 24000, lr: 0.0001, ups: 0.83, time: 02m 120ms, time_since_start: 55m 26s 677ms, eta: 07h 12m 39s 389ms
2022-05-06T15:52:20 | INFO | mmf.trainers.callbacks.logistics : progress: 3300/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 4.3289, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 28.8605, train/total_loss: 4.3289, train/total_loss/avg: 28.8605, max mem: 20584.0, experiment: run, epoch: 13, num_updates: 3300, iterations: 3300, max_updates: 24000, lr: 0.0001, ups: 0.85, time: 01m 57s 078ms, time_since_start: 57m 23s 756ms, eta: 06h 59m 40s 463ms
2022-05-06T15:53:57 | INFO | mmf.trainers.callbacks.logistics : progress: 3400/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 4.0733, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 28.1256, train/total_loss: 4.0733, train/total_loss/avg: 28.1256, max mem: 20584.0, experiment: run, epoch: 13, num_updates: 3400, iterations: 3400, max_updates: 24000, lr: 0.0001, ups: 1.03, time: 01m 37s 268ms, time_since_start: 59m 01s 024ms, eta: 05h 46m 58s 781ms
2022-05-06T15:55:38 | INFO | mmf.trainers.callbacks.logistics : progress: 3500/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 3.9555, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 27.4167, train/total_loss: 3.9555, train/total_loss/avg: 27.4167, max mem: 20584.0, experiment: run, epoch: 14, num_updates: 3500, iterations: 3500, max_updates: 24000, lr: 0.0001, ups: 0.99, time: 01m 41s 164ms, time_since_start: 01h 42s 189ms, eta: 05h 59m 07s 583ms
2022-05-06T15:57:18 | INFO | mmf.trainers.callbacks.logistics : progress: 3600/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 3.9293, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 26.7400, train/total_loss: 3.9293, train/total_loss/avg: 26.7400, max mem: 20584.0, experiment: run, epoch: 14, num_updates: 3600, iterations: 3600, max_updates: 24000, lr: 0.0001, ups: 1.00, time: 01m 40s 003ms, time_since_start: 01h 02m 22s 193ms, eta: 05h 53m 16s 352ms
2022-05-06T15:58:53 | INFO | mmf.trainers.callbacks.logistics : progress: 3700/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 3.8747, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 26.1097, train/total_loss: 3.8747, train/total_loss/avg: 26.1097, max mem: 20584.0, experiment: run, epoch: 14, num_updates: 3700, iterations: 3700, max_updates: 24000, lr: 0.0001, ups: 1.05, time: 01m 35s 206ms, time_since_start: 01h 03m 57s 399ms, eta: 05h 34m 40s 664ms
2022-05-06T16:00:39 | INFO | mmf.trainers.callbacks.logistics : progress: 3800/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 3.7845, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 25.5070, train/total_loss: 3.7845, train/total_loss/avg: 25.5070, max mem: 20584.0, experiment: run, epoch: 15, num_updates: 3800, iterations: 3800, max_updates: 24000, lr: 0.0001, ups: 0.95, time: 01m 45s 851ms, time_since_start: 01h 05m 43s 251ms, eta: 06h 10m 15s 916ms
2022-05-06T16:02:34 | INFO | mmf.trainers.callbacks.logistics : progress: 3900/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 3.7600, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 24.9314, train/total_loss: 3.7600, train/total_loss/avg: 24.9314, max mem: 20584.0, experiment: run, epoch: 15, num_updates: 3900, iterations: 3900, max_updates: 24000, lr: 0.0001, ups: 0.87, time: 01m 55s 233ms, time_since_start: 01h 07m 38s 484ms, eta: 06h 41m 05s 187ms
2022-05-06T16:04:30 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-06T16:04:30 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T16:04:31 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T16:04:36 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T16:04:36 | INFO | mmf.trainers.callbacks.logistics : progress: 4000/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 3.7431, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 24.3798, train/total_loss: 3.7431, train/total_loss/avg: 24.3798, max mem: 20584.0, experiment: run, epoch: 15, num_updates: 4000, iterations: 4000, max_updates: 24000, lr: 0.0001, ups: 0.83, time: 02m 01s 718ms, time_since_start: 01h 09m 40s 203ms, eta: 07h 01m 33s 171ms
2022-05-06T16:04:36 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-06T16:04:36 | INFO | mmf.common.test_reporter : Predicting for modality_hotpot
2022-05-06T16:06:22 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 39
2022-05-06T16:06:22 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-06T16:06:24 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T16:06:28 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T16:06:33 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T16:06:33 | INFO | mmf.trainers.callbacks.logistics : progress: 4000/24000, val/modality_hotpot/m4c_decoding_bce_with_mask: 5.6969, val/total_loss: 5.6969, val/modality_hotpot/textvqa_accuracy: 0.4489, num_updates: 4000, epoch: 15, iterations: 4000, max_updates: 24000, val_time: 01m 57s 299ms, best_update: 3000, best_iteration: 3000, best_val/modality_hotpot/textvqa_accuracy: 0.450660
2022-05-06T16:08:30 | INFO | mmf.trainers.callbacks.logistics : progress: 4100/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 3.7403, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 23.8516, train/total_loss: 3.7403, train/total_loss/avg: 23.8516, max mem: 20584.0, experiment: run, epoch: 16, num_updates: 4100, iterations: 4100, max_updates: 24000, lr: 0.0001, ups: 0.86, time: 01m 56s 794ms, time_since_start: 01h 13m 34s 302ms, eta: 06h 42m 28s 635ms
2022-05-06T16:10:28 | INFO | mmf.trainers.callbacks.logistics : progress: 4200/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 3.5479, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 23.3517, train/total_loss: 3.5479, train/total_loss/avg: 23.3517, max mem: 20584.0, experiment: run, epoch: 16, num_updates: 4200, iterations: 4200, max_updates: 24000, lr: 0.0001, ups: 0.85, time: 01m 57s 541ms, time_since_start: 01h 15m 31s 844ms, eta: 06h 43m 876ms
2022-05-06T16:12:16 | INFO | mmf.trainers.callbacks.logistics : progress: 4300/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 3.4192, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 22.8826, train/total_loss: 3.4192, train/total_loss/avg: 22.8826, max mem: 20584.0, experiment: run, epoch: 16, num_updates: 4300, iterations: 4300, max_updates: 24000, lr: 0.0001, ups: 0.93, time: 01m 48s 136ms, time_since_start: 01h 17m 19s 981ms, eta: 06h 08m 53s 776ms
2022-05-06T16:13:52 | INFO | mmf.trainers.callbacks.logistics : progress: 4400/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 3.3143, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 22.4231, train/total_loss: 3.3143, train/total_loss/avg: 22.4231, max mem: 20584.0, experiment: run, epoch: 17, num_updates: 4400, iterations: 4400, max_updates: 24000, lr: 0.0001, ups: 1.04, time: 01m 36s 529ms, time_since_start: 01h 18m 56s 510ms, eta: 05h 27m 37s 615ms
2022-05-06T16:15:29 | INFO | mmf.trainers.callbacks.logistics : progress: 4500/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 3.3104, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 21.9884, train/total_loss: 3.3104, train/total_loss/avg: 21.9884, max mem: 20584.0, experiment: run, epoch: 17, num_updates: 4500, iterations: 4500, max_updates: 24000, lr: 0.0001, ups: 1.04, time: 01m 36s 824ms, time_since_start: 01h 20m 33s 335ms, eta: 05h 26m 57s 229ms
2022-05-06T16:17:08 | INFO | mmf.trainers.callbacks.logistics : progress: 4600/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 3.2056, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 21.5604, train/total_loss: 3.2056, train/total_loss/avg: 21.5604, max mem: 20584.0, experiment: run, epoch: 18, num_updates: 4600, iterations: 4600, max_updates: 24000, lr: 0.0001, ups: 1.01, time: 01m 39s 116ms, time_since_start: 01h 22m 12s 452ms, eta: 05h 32m 58s 542ms
2022-05-06T16:18:49 | INFO | mmf.trainers.callbacks.logistics : progress: 4700/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 3.1838, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 21.1560, train/total_loss: 3.1838, train/total_loss/avg: 21.1560, max mem: 20584.0, experiment: run, epoch: 18, num_updates: 4700, iterations: 4700, max_updates: 24000, lr: 0.0001, ups: 1.00, time: 01m 40s 345ms, time_since_start: 01h 23m 52s 797ms, eta: 05h 35m 22s 007ms
2022-05-06T16:20:22 | INFO | mmf.trainers.callbacks.logistics : progress: 4800/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 3.0594, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 20.7707, train/total_loss: 3.0594, train/total_loss/avg: 20.7707, max mem: 20584.0, experiment: run, epoch: 18, num_updates: 4800, iterations: 4800, max_updates: 24000, lr: 0.0001, ups: 1.08, time: 01m 33s 199ms, time_since_start: 01h 25m 25s 997ms, eta: 05h 09m 52s 218ms
2022-05-06T16:21:58 | INFO | mmf.trainers.callbacks.logistics : progress: 4900/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 3.0567, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 20.3900, train/total_loss: 3.0567, train/total_loss/avg: 20.3900, max mem: 20584.0, experiment: run, epoch: 19, num_updates: 4900, iterations: 4900, max_updates: 24000, lr: 0.0001, ups: 1.04, time: 01m 36s 162ms, time_since_start: 01h 27m 02s 160ms, eta: 05h 18m 03s 407ms
2022-05-06T16:23:32 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-06T16:23:32 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T16:23:33 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T16:23:38 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T16:23:38 | INFO | mmf.trainers.callbacks.logistics : progress: 5000/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 2.8674, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 20.0314, train/total_loss: 2.8674, train/total_loss/avg: 20.0314, max mem: 20584.0, experiment: run, epoch: 19, num_updates: 5000, iterations: 5000, max_updates: 24000, lr: 0.0001, ups: 1.01, time: 01m 39s 679ms, time_since_start: 01h 28m 41s 839ms, eta: 05h 27m 57s 756ms
2022-05-06T16:23:38 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-06T16:23:38 | INFO | mmf.common.test_reporter : Predicting for modality_hotpot
2022-05-06T16:24:31 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 39
2022-05-06T16:24:31 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-06T16:24:33 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T16:24:38 | INFO | mmf.utils.checkpoint : Saving best checkpoint
2022-05-06T16:24:43 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T16:24:47 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T16:24:47 | INFO | mmf.trainers.callbacks.logistics : progress: 5000/24000, val/modality_hotpot/m4c_decoding_bce_with_mask: 5.7722, val/total_loss: 5.7722, val/modality_hotpot/textvqa_accuracy: 0.4533, num_updates: 5000, epoch: 19, iterations: 5000, max_updates: 24000, val_time: 01m 09s 820ms, best_update: 5000, best_iteration: 5000, best_val/modality_hotpot/textvqa_accuracy: 0.453320
2022-05-06T16:26:19 | INFO | mmf.trainers.callbacks.logistics : progress: 5100/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 2.8645, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 19.6871, train/total_loss: 2.8645, train/total_loss/avg: 19.6871, max mem: 20595.0, experiment: run, epoch: 19, num_updates: 5100, iterations: 5100, max_updates: 24000, lr: 0.0001, ups: 1.10, time: 01m 31s 673ms, time_since_start: 01h 31m 23s 334ms, eta: 05h 01s 973ms
2022-05-06T16:27:57 | INFO | mmf.trainers.callbacks.logistics : progress: 5200/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 2.8530, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 19.3498, train/total_loss: 2.8530, train/total_loss/avg: 19.3498, max mem: 20595.0, experiment: run, epoch: 20, num_updates: 5200, iterations: 5200, max_updates: 24000, lr: 0.0001, ups: 1.02, time: 01m 38s 356ms, time_since_start: 01h 33m 01s 691ms, eta: 05h 20m 12s 103ms
2022-05-06T16:29:30 | INFO | mmf.trainers.callbacks.logistics : progress: 5300/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 2.7242, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 19.0296, train/total_loss: 2.7242, train/total_loss/avg: 19.0296, max mem: 20595.0, experiment: run, epoch: 20, num_updates: 5300, iterations: 5300, max_updates: 24000, lr: 0.0001, ups: 1.09, time: 01m 32s 432ms, time_since_start: 01h 34m 34s 123ms, eta: 04h 59m 18s 952ms
2022-05-06T16:31:06 | INFO | mmf.trainers.callbacks.logistics : progress: 5400/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 2.6642, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 18.7135, train/total_loss: 2.6642, train/total_loss/avg: 18.7135, max mem: 20595.0, experiment: run, epoch: 21, num_updates: 5400, iterations: 5400, max_updates: 24000, lr: 0.0001, ups: 1.05, time: 01m 35s 853ms, time_since_start: 01h 36m 09s 977ms, eta: 05h 08m 44s 171ms
2022-05-06T16:32:39 | INFO | mmf.trainers.callbacks.logistics : progress: 5500/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 2.6610, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 18.4070, train/total_loss: 2.6610, train/total_loss/avg: 18.4070, max mem: 20595.0, experiment: run, epoch: 21, num_updates: 5500, iterations: 5500, max_updates: 24000, lr: 0.0001, ups: 1.08, time: 01m 33s 394ms, time_since_start: 01h 37m 43s 372ms, eta: 04h 59m 11s 872ms
2022-05-06T16:34:12 | INFO | mmf.trainers.callbacks.logistics : progress: 5600/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 2.5548, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 18.1126, train/total_loss: 2.5548, train/total_loss/avg: 18.1126, max mem: 20595.0, experiment: run, epoch: 21, num_updates: 5600, iterations: 5600, max_updates: 24000, lr: 0.0001, ups: 1.08, time: 01m 33s 061ms, time_since_start: 01h 39m 16s 434ms, eta: 04h 56m 31s 204ms
2022-05-06T16:35:53 | INFO | mmf.trainers.callbacks.logistics : progress: 5700/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 2.4732, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 17.8287, train/total_loss: 2.4732, train/total_loss/avg: 17.8287, max mem: 20595.0, experiment: run, epoch: 22, num_updates: 5700, iterations: 5700, max_updates: 24000, lr: 0.0001, ups: 0.99, time: 01m 41s 165ms, time_since_start: 01h 40m 57s 599ms, eta: 05h 20m 35s 345ms
2022-05-06T16:37:33 | INFO | mmf.trainers.callbacks.logistics : progress: 5800/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 2.4575, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 17.5565, train/total_loss: 2.4575, train/total_loss/avg: 17.5565, max mem: 20595.0, experiment: run, epoch: 22, num_updates: 5800, iterations: 5800, max_updates: 24000, lr: 0.0001, ups: 1.01, time: 01m 39s 646ms, time_since_start: 01h 42m 37s 246ms, eta: 05h 14m 03s 010ms
2022-05-06T16:39:06 | INFO | mmf.trainers.callbacks.logistics : progress: 5900/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 2.3779, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 17.2883, train/total_loss: 2.3779, train/total_loss/avg: 17.2883, max mem: 20595.0, experiment: run, epoch: 22, num_updates: 5900, iterations: 5900, max_updates: 24000, lr: 0.0001, ups: 1.08, time: 01m 33s 436ms, time_since_start: 01h 44m 10s 682ms, eta: 04h 52m 51s 529ms
2022-05-06T16:40:43 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-06T16:40:43 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T16:40:44 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T16:40:46 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T16:40:46 | INFO | mmf.trainers.callbacks.logistics : progress: 6000/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 2.2972, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 17.0312, train/total_loss: 2.2972, train/total_loss/avg: 17.0312, max mem: 20595.0, experiment: run, epoch: 23, num_updates: 6000, iterations: 6000, max_updates: 24000, lr: 0.0001, ups: 1.01, time: 01m 39s 897ms, time_since_start: 01h 45m 50s 580ms, eta: 05h 11m 22s 791ms
2022-05-06T16:40:46 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-06T16:40:46 | INFO | mmf.common.test_reporter : Predicting for modality_hotpot
2022-05-06T16:41:39 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 39
2022-05-06T16:41:39 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-06T16:41:41 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T16:41:45 | INFO | mmf.utils.checkpoint : Saving best checkpoint
2022-05-06T16:41:50 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T16:41:55 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T16:41:55 | INFO | mmf.trainers.callbacks.logistics : progress: 6000/24000, val/modality_hotpot/m4c_decoding_bce_with_mask: 6.0641, val/total_loss: 6.0641, val/modality_hotpot/textvqa_accuracy: 0.4561, num_updates: 6000, epoch: 23, iterations: 6000, max_updates: 24000, val_time: 01m 08s 925ms, best_update: 6000, best_iteration: 6000, best_val/modality_hotpot/textvqa_accuracy: 0.456120
2022-05-06T16:43:26 | INFO | mmf.trainers.callbacks.logistics : progress: 6100/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 2.1481, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 16.7793, train/total_loss: 2.1481, train/total_loss/avg: 16.7793, max mem: 20597.0, experiment: run, epoch: 23, num_updates: 6100, iterations: 6100, max_updates: 24000, lr: 0.0001, ups: 1.11, time: 01m 30s 823ms, time_since_start: 01h 48m 30s 330ms, eta: 04h 41m 31s 453ms
2022-05-06T16:45:04 | INFO | mmf.trainers.callbacks.logistics : progress: 6200/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 2.1148, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 16.5338, train/total_loss: 2.1148, train/total_loss/avg: 16.5338, max mem: 20597.0, experiment: run, epoch: 24, num_updates: 6200, iterations: 6200, max_updates: 24000, lr: 0.0001, ups: 1.02, time: 01m 38s 045ms, time_since_start: 01h 50m 08s 375ms, eta: 05h 02m 12s 665ms
2022-05-06T16:46:41 | INFO | mmf.trainers.callbacks.logistics : progress: 6300/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 2.0418, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 16.2971, train/total_loss: 2.0418, train/total_loss/avg: 16.2971, max mem: 20597.0, experiment: run, epoch: 24, num_updates: 6300, iterations: 6300, max_updates: 24000, lr: 0.0001, ups: 1.04, time: 01m 36s 555ms, time_since_start: 01h 51m 44s 931ms, eta: 04h 55m 56s 843ms
2022-05-06T16:48:18 | INFO | mmf.trainers.callbacks.logistics : progress: 6400/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.9647, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 16.0667, train/total_loss: 1.9647, train/total_loss/avg: 16.0667, max mem: 20597.0, experiment: run, epoch: 24, num_updates: 6400, iterations: 6400, max_updates: 24000, lr: 0.0001, ups: 1.03, time: 01m 37s 095ms, time_since_start: 01h 53m 22s 027ms, eta: 04h 55m 55s 355ms
2022-05-06T16:49:54 | INFO | mmf.trainers.callbacks.logistics : progress: 6500/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.9277, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 15.8471, train/total_loss: 1.9277, train/total_loss/avg: 15.8471, max mem: 20597.0, experiment: run, epoch: 25, num_updates: 6500, iterations: 6500, max_updates: 24000, lr: 0.0001, ups: 1.05, time: 01m 35s 879ms, time_since_start: 01h 54m 57s 907ms, eta: 04h 50m 33s 322ms
2022-05-06T16:51:30 | INFO | mmf.trainers.callbacks.logistics : progress: 6600/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.9208, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 15.6313, train/total_loss: 1.9208, train/total_loss/avg: 15.6313, max mem: 20597.0, experiment: run, epoch: 25, num_updates: 6600, iterations: 6600, max_updates: 24000, lr: 0.0001, ups: 1.04, time: 01m 36s 435ms, time_since_start: 01h 56m 34s 342ms, eta: 04h 50m 34s 116ms
2022-05-06T16:53:09 | INFO | mmf.trainers.callbacks.logistics : progress: 6700/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.8608, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 15.4248, train/total_loss: 1.8608, train/total_loss/avg: 15.4248, max mem: 20597.0, experiment: run, epoch: 25, num_updates: 6700, iterations: 6700, max_updates: 24000, lr: 0.0001, ups: 1.01, time: 01m 39s 006ms, time_since_start: 01h 58m 13s 349ms, eta: 04h 56m 36s 173ms
2022-05-06T16:54:47 | INFO | mmf.trainers.callbacks.logistics : progress: 6800/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.8538, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 15.2203, train/total_loss: 1.8538, train/total_loss/avg: 15.2203, max mem: 20597.0, experiment: run, epoch: 26, num_updates: 6800, iterations: 6800, max_updates: 24000, lr: 0.0001, ups: 1.02, time: 01m 38s 301ms, time_since_start: 01h 59m 51s 650ms, eta: 04h 52m 47s 284ms
2022-05-06T16:56:23 | INFO | mmf.trainers.callbacks.logistics : progress: 6900/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.7975, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 15.0243, train/total_loss: 1.7975, train/total_loss/avg: 15.0243, max mem: 20597.0, experiment: run, epoch: 26, num_updates: 6900, iterations: 6900, max_updates: 24000, lr: 0.0001, ups: 1.05, time: 01m 35s 351ms, time_since_start: 02h 01m 27s 002ms, eta: 04h 42m 21s 097ms
2022-05-06T16:58:00 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-06T16:58:00 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T16:58:01 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T16:58:06 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T16:58:06 | INFO | mmf.trainers.callbacks.logistics : progress: 7000/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.7881, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 14.8300, train/total_loss: 1.7881, train/total_loss/avg: 14.8300, max mem: 20597.0, experiment: run, epoch: 27, num_updates: 7000, iterations: 7000, max_updates: 24000, lr: 0.0001, ups: 0.98, time: 01m 42s 849ms, time_since_start: 02h 03m 09s 851ms, eta: 05h 02m 46s 247ms
2022-05-06T16:58:06 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-06T16:58:06 | INFO | mmf.common.test_reporter : Predicting for modality_hotpot
2022-05-06T16:58:59 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 39
2022-05-06T16:58:59 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-06T16:59:01 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T16:59:05 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T16:59:10 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T16:59:10 | INFO | mmf.trainers.callbacks.logistics : progress: 7000/24000, val/modality_hotpot/m4c_decoding_bce_with_mask: 6.2387, val/total_loss: 6.2387, val/modality_hotpot/textvqa_accuracy: 0.4530, num_updates: 7000, epoch: 27, iterations: 7000, max_updates: 24000, val_time: 01m 04s 571ms, best_update: 6000, best_iteration: 6000, best_val/modality_hotpot/textvqa_accuracy: 0.456120
2022-05-06T17:00:41 | INFO | mmf.trainers.callbacks.logistics : progress: 7100/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.7340, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 14.6437, train/total_loss: 1.7340, train/total_loss/avg: 14.6437, max mem: 20597.0, experiment: run, epoch: 27, num_updates: 7100, iterations: 7100, max_updates: 24000, lr: 0.0001, ups: 1.10, time: 01m 31s 111ms, time_since_start: 02h 05m 45s 536ms, eta: 04h 26m 38s 451ms
2022-05-06T17:02:15 | INFO | mmf.trainers.callbacks.logistics : progress: 7200/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.7340, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 14.4647, train/total_loss: 1.7340, train/total_loss/avg: 14.4647, max mem: 20597.0, experiment: run, epoch: 27, num_updates: 7200, iterations: 7200, max_updates: 24000, lr: 0.0001, ups: 1.08, time: 01m 33s 186ms, time_since_start: 02h 07m 18s 722ms, eta: 04h 31m 05s 857ms
2022-05-06T17:03:50 | INFO | mmf.trainers.callbacks.logistics : progress: 7300/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.6966, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 14.2854, train/total_loss: 1.6966, train/total_loss/avg: 14.2854, max mem: 20597.0, experiment: run, epoch: 28, num_updates: 7300, iterations: 7300, max_updates: 24000, lr: 0.0001, ups: 1.05, time: 01m 35s 248ms, time_since_start: 02h 08m 53s 971ms, eta: 04h 35m 26s 887ms
2022-05-06T17:05:22 | INFO | mmf.trainers.callbacks.logistics : progress: 7400/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.6690, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 14.1146, train/total_loss: 1.6690, train/total_loss/avg: 14.1146, max mem: 20597.0, experiment: run, epoch: 28, num_updates: 7400, iterations: 7400, max_updates: 24000, lr: 0.0001, ups: 1.09, time: 01m 32s 664ms, time_since_start: 02h 10m 26s 635ms, eta: 04h 26m 22s 148ms
2022-05-06T17:06:56 | INFO | mmf.trainers.callbacks.logistics : progress: 7500/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.6455, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 13.9468, train/total_loss: 1.6455, train/total_loss/avg: 13.9468, max mem: 20597.0, experiment: run, epoch: 28, num_updates: 7500, iterations: 7500, max_updates: 24000, lr: 0.0001, ups: 1.08, time: 01m 33s 604ms, time_since_start: 02h 12m 240ms, eta: 04h 27m 27s 072ms
2022-05-06T17:08:35 | INFO | mmf.trainers.callbacks.logistics : progress: 7600/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.6239, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 13.7844, train/total_loss: 1.6239, train/total_loss/avg: 13.7844, max mem: 20597.0, experiment: run, epoch: 29, num_updates: 7600, iterations: 7600, max_updates: 24000, lr: 0.0001, ups: 1.02, time: 01m 38s 615ms, time_since_start: 02h 13m 38s 855ms, eta: 04h 40m 03s 762ms
2022-05-06T17:10:05 | INFO | mmf.trainers.callbacks.logistics : progress: 7700/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.6036, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 13.6236, train/total_loss: 1.6036, train/total_loss/avg: 13.6236, max mem: 20597.0, experiment: run, epoch: 29, num_updates: 7700, iterations: 7700, max_updates: 24000, lr: 0.0001, ups: 1.11, time: 01m 30s 609ms, time_since_start: 02h 15m 09s 465ms, eta: 04h 15m 45s 323ms
2022-05-06T17:11:38 | INFO | mmf.trainers.callbacks.logistics : progress: 7800/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.6001, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 13.4670, train/total_loss: 1.6001, train/total_loss/avg: 13.4670, max mem: 20597.0, experiment: run, epoch: 29, num_updates: 7800, iterations: 7800, max_updates: 24000, lr: 0.0001, ups: 1.09, time: 01m 32s 959ms, time_since_start: 02h 16m 42s 424ms, eta: 04h 20m 46s 741ms
2022-05-06T17:13:14 | INFO | mmf.trainers.callbacks.logistics : progress: 7900/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.5993, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 13.3136, train/total_loss: 1.5993, train/total_loss/avg: 13.3136, max mem: 20597.0, experiment: run, epoch: 30, num_updates: 7900, iterations: 7900, max_updates: 24000, lr: 0.0001, ups: 1.05, time: 01m 35s 490ms, time_since_start: 02h 18m 17s 915ms, eta: 04h 26m 13s 558ms
2022-05-06T17:14:46 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-06T17:14:46 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T17:14:48 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T17:14:52 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T17:14:52 | INFO | mmf.trainers.callbacks.logistics : progress: 8000/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.5550, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 13.1621, train/total_loss: 1.5550, train/total_loss/avg: 13.1621, max mem: 20597.0, experiment: run, epoch: 30, num_updates: 8000, iterations: 8000, max_updates: 24000, lr: 0.0001, ups: 1.02, time: 01m 38s 640ms, time_since_start: 02h 19m 56s 556ms, eta: 04h 33m 18s 051ms
2022-05-06T17:14:52 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-06T17:14:52 | INFO | mmf.common.test_reporter : Predicting for modality_hotpot
2022-05-06T17:15:45 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 39
2022-05-06T17:15:45 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-06T17:15:47 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T17:15:52 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T17:15:57 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T17:15:57 | INFO | mmf.trainers.callbacks.logistics : progress: 8000/24000, val/modality_hotpot/m4c_decoding_bce_with_mask: 6.2477, val/total_loss: 6.2477, val/modality_hotpot/textvqa_accuracy: 0.4550, num_updates: 8000, epoch: 30, iterations: 8000, max_updates: 24000, val_time: 01m 04s 532ms, best_update: 6000, best_iteration: 6000, best_val/modality_hotpot/textvqa_accuracy: 0.456120
2022-05-06T17:17:29 | INFO | mmf.trainers.callbacks.logistics : progress: 8100/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.5532, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 13.0160, train/total_loss: 1.5532, train/total_loss/avg: 13.0160, max mem: 20597.0, experiment: run, epoch: 31, num_updates: 8100, iterations: 8100, max_updates: 24000, lr: 0.0001, ups: 1.09, time: 01m 32s 517ms, time_since_start: 02h 22m 33s 608ms, eta: 04h 14m 43s 983ms
2022-05-06T17:19:02 | INFO | mmf.trainers.callbacks.logistics : progress: 8200/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.5360, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 12.8752, train/total_loss: 1.5360, train/total_loss/avg: 12.8752, max mem: 20597.0, experiment: run, epoch: 31, num_updates: 8200, iterations: 8200, max_updates: 24000, lr: 0.0001, ups: 1.09, time: 01m 32s 233ms, time_since_start: 02h 24m 05s 841ms, eta: 04h 12m 21s 254ms
2022-05-06T17:20:35 | INFO | mmf.trainers.callbacks.logistics : progress: 8300/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.5224, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 12.7355, train/total_loss: 1.5224, train/total_loss/avg: 12.7355, max mem: 20597.0, experiment: run, epoch: 31, num_updates: 8300, iterations: 8300, max_updates: 24000, lr: 0.0001, ups: 1.08, time: 01m 33s 007ms, time_since_start: 02h 25m 38s 849ms, eta: 04h 12m 51s 682ms
2022-05-06T17:22:13 | INFO | mmf.trainers.callbacks.logistics : progress: 8400/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.4767, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 12.6007, train/total_loss: 1.4767, train/total_loss/avg: 12.6007, max mem: 20597.0, experiment: run, epoch: 32, num_updates: 8400, iterations: 8400, max_updates: 24000, lr: 0.0001, ups: 1.02, time: 01m 38s 081ms, time_since_start: 02h 27m 16s 930ms, eta: 04h 24m 57s 407ms
2022-05-06T17:23:49 | INFO | mmf.trainers.callbacks.logistics : progress: 8500/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.4217, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 12.4658, train/total_loss: 1.4217, train/total_loss/avg: 12.4658, max mem: 20597.0, experiment: run, epoch: 32, num_updates: 8500, iterations: 8500, max_updates: 24000, lr: 0.0001, ups: 1.04, time: 01m 36s 174ms, time_since_start: 02h 28m 53s 105ms, eta: 04h 18m 08s 432ms
2022-05-06T17:25:25 | INFO | mmf.trainers.callbacks.logistics : progress: 8600/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.4159, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 12.3333, train/total_loss: 1.4159, train/total_loss/avg: 12.3333, max mem: 20597.0, experiment: run, epoch: 32, num_updates: 8600, iterations: 8600, max_updates: 24000, lr: 0.0001, ups: 1.05, time: 01m 35s 679ms, time_since_start: 02h 30m 28s 784ms, eta: 04h 15m 09s 317ms
2022-05-06T17:27:01 | INFO | mmf.trainers.callbacks.logistics : progress: 8700/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.4084, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 12.2058, train/total_loss: 1.4084, train/total_loss/avg: 12.2058, max mem: 20597.0, experiment: run, epoch: 33, num_updates: 8700, iterations: 8700, max_updates: 24000, lr: 0.0001, ups: 1.04, time: 01m 36s 722ms, time_since_start: 02h 32m 05s 507ms, eta: 04h 16m 15s 716ms
2022-05-06T17:28:36 | INFO | mmf.trainers.callbacks.logistics : progress: 8800/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.4014, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 12.0807, train/total_loss: 1.4014, train/total_loss/avg: 12.0807, max mem: 20597.0, experiment: run, epoch: 33, num_updates: 8800, iterations: 8800, max_updates: 24000, lr: 0.0001, ups: 1.06, time: 01m 34s 635ms, time_since_start: 02h 33m 40s 143ms, eta: 04h 09m 05s 662ms
2022-05-06T17:30:12 | INFO | mmf.trainers.callbacks.logistics : progress: 8900/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.3726, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 11.9568, train/total_loss: 1.3726, train/total_loss/avg: 11.9568, max mem: 20597.0, experiment: run, epoch: 34, num_updates: 8900, iterations: 8900, max_updates: 24000, lr: 0.0001, ups: 1.05, time: 01m 35s 765ms, time_since_start: 02h 35m 15s 909ms, eta: 04h 10m 24s 629ms
2022-05-06T17:31:45 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-06T17:31:45 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T17:31:46 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T17:31:51 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T17:31:51 | INFO | mmf.trainers.callbacks.logistics : progress: 9000/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.3558, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 11.8359, train/total_loss: 1.3558, train/total_loss/avg: 11.8359, max mem: 20597.0, experiment: run, epoch: 34, num_updates: 9000, iterations: 9000, max_updates: 24000, lr: 0.0001, ups: 1.01, time: 01m 39s 210ms, time_since_start: 02h 36m 55s 120ms, eta: 04h 17m 42s 004ms
2022-05-06T17:31:51 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-06T17:31:51 | INFO | mmf.common.test_reporter : Predicting for modality_hotpot
2022-05-06T17:32:44 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 39
2022-05-06T17:32:44 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-06T17:32:46 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T17:32:50 | INFO | mmf.utils.checkpoint : Saving best checkpoint
2022-05-06T17:32:55 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T17:33:00 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T17:33:00 | INFO | mmf.trainers.callbacks.logistics : progress: 9000/24000, val/modality_hotpot/m4c_decoding_bce_with_mask: 6.3070, val/total_loss: 6.3070, val/modality_hotpot/textvqa_accuracy: 0.4595, num_updates: 9000, epoch: 34, iterations: 9000, max_updates: 24000, val_time: 01m 08s 688ms, best_update: 9000, best_iteration: 9000, best_val/modality_hotpot/textvqa_accuracy: 0.459460
2022-05-06T17:34:31 | INFO | mmf.trainers.callbacks.logistics : progress: 9100/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.3250, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 11.7188, train/total_loss: 1.3250, train/total_loss/avg: 11.7188, max mem: 20597.0, experiment: run, epoch: 34, num_updates: 9100, iterations: 9100, max_updates: 24000, lr: 0.0001, ups: 1.10, time: 01m 31s 121ms, time_since_start: 02h 39m 34s 931ms, eta: 03h 55m 06s 571ms
2022-05-06T17:36:08 | INFO | mmf.trainers.callbacks.logistics : progress: 9200/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.2741, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 11.6031, train/total_loss: 1.2741, train/total_loss/avg: 11.6031, max mem: 20597.0, experiment: run, epoch: 35, num_updates: 9200, iterations: 9200, max_updates: 24000, lr: 0.0001, ups: 1.04, time: 01m 36s 991ms, time_since_start: 02h 41m 11s 923ms, eta: 04h 08m 34s 609ms
2022-05-06T17:37:42 | INFO | mmf.trainers.callbacks.logistics : progress: 9300/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.2409, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 11.4906, train/total_loss: 1.2409, train/total_loss/avg: 11.4906, max mem: 20597.0, experiment: run, epoch: 35, num_updates: 9300, iterations: 9300, max_updates: 24000, lr: 0.0001, ups: 1.08, time: 01m 33s 897ms, time_since_start: 02h 42m 45s 820ms, eta: 03h 59m 01s 211ms
2022-05-06T17:39:14 | INFO | mmf.trainers.callbacks.logistics : progress: 9400/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.2409, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 11.3817, train/total_loss: 1.2409, train/total_loss/avg: 11.3817, max mem: 20597.0, experiment: run, epoch: 35, num_updates: 9400, iterations: 9400, max_updates: 24000, lr: 0.0001, ups: 1.09, time: 01m 32s 545ms, time_since_start: 02h 44m 18s 366ms, eta: 03h 53m 58s 666ms
2022-05-06T17:40:49 | INFO | mmf.trainers.callbacks.logistics : progress: 9500/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.1994, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 11.2743, train/total_loss: 1.1994, train/total_loss/avg: 11.2743, max mem: 20597.0, experiment: run, epoch: 36, num_updates: 9500, iterations: 9500, max_updates: 24000, lr: 0.0001, ups: 1.06, time: 01m 34s 344ms, time_since_start: 02h 45m 52s 710ms, eta: 03h 56m 53s 428ms
2022-05-06T17:42:24 | INFO | mmf.trainers.callbacks.logistics : progress: 9600/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.1905, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 11.1692, train/total_loss: 1.1905, train/total_loss/avg: 11.1692, max mem: 20597.0, experiment: run, epoch: 36, num_updates: 9600, iterations: 9600, max_updates: 24000, lr: 0.0001, ups: 1.05, time: 01m 35s 373ms, time_since_start: 02h 47m 28s 084ms, eta: 03h 57m 49s 475ms
2022-05-06T17:43:56 | INFO | mmf.trainers.callbacks.logistics : progress: 9700/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.1865, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 11.0656, train/total_loss: 1.1865, train/total_loss/avg: 11.0656, max mem: 20597.0, experiment: run, epoch: 37, num_updates: 9700, iterations: 9700, max_updates: 24000, lr: 0.0001, ups: 1.10, time: 01m 31s 937ms, time_since_start: 02h 49m 022ms, eta: 03h 47m 39s 861ms
2022-05-06T17:45:30 | INFO | mmf.trainers.callbacks.logistics : progress: 9800/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.1815, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 10.9647, train/total_loss: 1.1815, train/total_loss/avg: 10.9647, max mem: 20597.0, experiment: run, epoch: 37, num_updates: 9800, iterations: 9800, max_updates: 24000, lr: 0.0001, ups: 1.06, time: 01m 34s 659ms, time_since_start: 02h 50m 34s 682ms, eta: 03h 52m 45s 856ms
2022-05-06T17:47:03 | INFO | mmf.trainers.callbacks.logistics : progress: 9900/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.1793, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 10.8646, train/total_loss: 1.1793, train/total_loss/avg: 10.8646, max mem: 20597.0, experiment: run, epoch: 37, num_updates: 9900, iterations: 9900, max_updates: 24000, lr: 0.0001, ups: 1.09, time: 01m 32s 948ms, time_since_start: 02h 52m 07s 630ms, eta: 03h 46m 56s 914ms
2022-05-06T17:48:39 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-06T17:48:39 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T17:48:40 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T17:48:47 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T17:48:47 | INFO | mmf.trainers.callbacks.logistics : progress: 10000/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.1722, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 10.7670, train/total_loss: 1.1722, train/total_loss/avg: 10.7670, max mem: 20597.0, experiment: run, epoch: 38, num_updates: 10000, iterations: 10000, max_updates: 24000, lr: 0.0001, ups: 0.97, time: 01m 43s 080ms, time_since_start: 02h 53m 50s 711ms, eta: 04h 09m 54s 121ms
2022-05-06T17:48:47 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-06T17:48:47 | INFO | mmf.common.test_reporter : Predicting for modality_hotpot
2022-05-06T17:49:40 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 39
2022-05-06T17:49:40 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-06T17:49:43 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T17:49:47 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T17:49:52 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T17:49:52 | INFO | mmf.trainers.callbacks.logistics : progress: 10000/24000, val/modality_hotpot/m4c_decoding_bce_with_mask: 6.5109, val/total_loss: 6.5109, val/modality_hotpot/textvqa_accuracy: 0.4562, num_updates: 10000, epoch: 38, iterations: 10000, max_updates: 24000, val_time: 01m 05s 248ms, best_update: 9000, best_iteration: 9000, best_val/modality_hotpot/textvqa_accuracy: 0.459460
2022-05-06T17:51:25 | INFO | mmf.trainers.callbacks.logistics : progress: 10100/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.1447, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 10.6696, train/total_loss: 1.1447, train/total_loss/avg: 10.6696, max mem: 20597.0, experiment: run, epoch: 38, num_updates: 10100, iterations: 10100, max_updates: 24000, lr: 0.0001, ups: 1.08, time: 01m 33s 252ms, time_since_start: 02h 56m 29s 213ms, eta: 03h 44m 27s 607ms
2022-05-06T17:53:00 | INFO | mmf.trainers.callbacks.logistics : progress: 10200/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.1350, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 10.5757, train/total_loss: 1.1350, train/total_loss/avg: 10.5757, max mem: 20597.0, experiment: run, epoch: 38, num_updates: 10200, iterations: 10200, max_updates: 24000, lr: 0.0001, ups: 1.05, time: 01m 35s 052ms, time_since_start: 02h 58m 04s 266ms, eta: 03h 47m 08s 789ms
2022-05-06T17:54:35 | INFO | mmf.trainers.callbacks.logistics : progress: 10300/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.1226, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 10.4817, train/total_loss: 1.1226, train/total_loss/avg: 10.4817, max mem: 20597.0, experiment: run, epoch: 39, num_updates: 10300, iterations: 10300, max_updates: 24000, lr: 0.0001, ups: 1.06, time: 01m 34s 935ms, time_since_start: 02h 59m 39s 201ms, eta: 03h 45m 13s 391ms
2022-05-06T17:56:10 | INFO | mmf.trainers.callbacks.logistics : progress: 10400/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.1226, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 10.3924, train/total_loss: 1.1226, train/total_loss/avg: 10.3924, max mem: 20597.0, experiment: run, epoch: 39, num_updates: 10400, iterations: 10400, max_updates: 24000, lr: 0.0001, ups: 1.06, time: 01m 34s 807ms, time_since_start: 03h 01m 14s 009ms, eta: 03h 43m 16s 702ms
2022-05-06T17:57:47 | INFO | mmf.trainers.callbacks.logistics : progress: 10500/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.1055, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 10.3030, train/total_loss: 1.1055, train/total_loss/avg: 10.3030, max mem: 20597.0, experiment: run, epoch: 40, num_updates: 10500, iterations: 10500, max_updates: 24000, lr: 0.0001, ups: 1.03, time: 01m 37s 349ms, time_since_start: 03h 02m 51s 358ms, eta: 03h 47m 34s 727ms
2022-05-06T17:59:17 | INFO | mmf.trainers.callbacks.logistics : progress: 10600/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.1226, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 10.2168, train/total_loss: 1.1226, train/total_loss/avg: 10.2168, max mem: 20597.0, experiment: run, epoch: 40, num_updates: 10600, iterations: 10600, max_updates: 24000, lr: 0.0001, ups: 1.11, time: 01m 30s 091ms, time_since_start: 03h 04m 21s 450ms, eta: 03h 29m 03s 123ms
2022-05-06T18:00:48 | INFO | mmf.trainers.callbacks.logistics : progress: 10700/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.1055, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 10.1316, train/total_loss: 1.1055, train/total_loss/avg: 10.1316, max mem: 20597.0, experiment: run, epoch: 40, num_updates: 10700, iterations: 10700, max_updates: 24000, lr: 0.0001, ups: 1.10, time: 01m 31s 039ms, time_since_start: 03h 05m 52s 490ms, eta: 03h 29m 40s 517ms
2022-05-06T18:02:22 | INFO | mmf.trainers.callbacks.logistics : progress: 10800/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.1017, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 10.0473, train/total_loss: 1.1017, train/total_loss/avg: 10.0473, max mem: 20597.0, experiment: run, epoch: 41, num_updates: 10800, iterations: 10800, max_updates: 24000, lr: 0.0001, ups: 1.08, time: 01m 33s 438ms, time_since_start: 03h 07m 25s 928ms, eta: 03h 33m 34s 897ms
2022-05-06T18:03:56 | INFO | mmf.trainers.callbacks.logistics : progress: 10900/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.1017, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 9.9644, train/total_loss: 1.1017, train/total_loss/avg: 9.9644, max mem: 20597.0, experiment: run, epoch: 41, num_updates: 10900, iterations: 10900, max_updates: 24000, lr: 0.0001, ups: 1.06, time: 01m 34s 500ms, time_since_start: 03h 09m 429ms, eta: 03h 34m 22s 396ms
2022-05-06T18:05:29 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-06T18:05:29 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T18:05:30 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T18:05:35 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T18:05:35 | INFO | mmf.trainers.callbacks.logistics : progress: 11000/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.1017, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 9.8818, train/total_loss: 1.1017, train/total_loss/avg: 9.8818, max mem: 20597.0, experiment: run, epoch: 41, num_updates: 11000, iterations: 11000, max_updates: 24000, lr: 0.0001, ups: 1.01, time: 01m 39s 214ms, time_since_start: 03h 10m 39s 644ms, eta: 03h 43m 20s 915ms
2022-05-06T18:05:35 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-06T18:05:35 | INFO | mmf.common.test_reporter : Predicting for modality_hotpot
2022-05-06T18:06:28 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 39
2022-05-06T18:06:28 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-06T18:06:30 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T18:06:35 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T18:06:40 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T18:06:40 | INFO | mmf.trainers.callbacks.logistics : progress: 11000/24000, val/modality_hotpot/m4c_decoding_bce_with_mask: 6.6205, val/total_loss: 6.6205, val/modality_hotpot/textvqa_accuracy: 0.4522, num_updates: 11000, epoch: 41, iterations: 11000, max_updates: 24000, val_time: 01m 04s 243ms, best_update: 9000, best_iteration: 9000, best_val/modality_hotpot/textvqa_accuracy: 0.459460
2022-05-06T18:08:12 | INFO | mmf.trainers.callbacks.logistics : progress: 11100/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.1017, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 9.8041, train/total_loss: 1.1017, train/total_loss/avg: 9.8041, max mem: 20597.0, experiment: run, epoch: 42, num_updates: 11100, iterations: 11100, max_updates: 24000, lr: 0.0001, ups: 1.09, time: 01m 32s 212ms, time_since_start: 03h 13m 16s 101ms, eta: 03h 25m 59s 271ms
2022-05-06T18:09:46 | INFO | mmf.trainers.callbacks.logistics : progress: 11200/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.1055, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 9.7271, train/total_loss: 1.1055, train/total_loss/avg: 9.7271, max mem: 20597.0, experiment: run, epoch: 42, num_updates: 11200, iterations: 11200, max_updates: 24000, lr: 0.0001, ups: 1.06, time: 01m 34s 076ms, time_since_start: 03h 14m 50s 177ms, eta: 03h 28m 31s 444ms
2022-05-06T18:11:22 | INFO | mmf.trainers.callbacks.logistics : progress: 11300/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.1055, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 9.6510, train/total_loss: 1.1055, train/total_loss/avg: 9.6510, max mem: 20597.0, experiment: run, epoch: 43, num_updates: 11300, iterations: 11300, max_updates: 24000, lr: 0.0001, ups: 1.05, time: 01m 35s 748ms, time_since_start: 03h 16m 25s 925ms, eta: 03h 30m 34s 260ms
2022-05-06T18:12:55 | INFO | mmf.trainers.callbacks.logistics : progress: 11400/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.1017, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 9.5748, train/total_loss: 1.1017, train/total_loss/avg: 9.5748, max mem: 20597.0, experiment: run, epoch: 43, num_updates: 11400, iterations: 11400, max_updates: 24000, lr: 0.0001, ups: 1.08, time: 01m 33s 670ms, time_since_start: 03h 17m 59s 596ms, eta: 03h 24m 22s 815ms
2022-05-06T18:14:29 | INFO | mmf.trainers.callbacks.logistics : progress: 11500/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.0962, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 9.4998, train/total_loss: 1.0962, train/total_loss/avg: 9.4998, max mem: 20597.0, experiment: run, epoch: 43, num_updates: 11500, iterations: 11500, max_updates: 24000, lr: 0.0001, ups: 1.08, time: 01m 33s 656ms, time_since_start: 03h 19m 33s 253ms, eta: 03h 22m 43s 629ms
2022-05-06T18:16:02 | INFO | mmf.trainers.callbacks.logistics : progress: 11600/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.0591, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 9.4249, train/total_loss: 1.0591, train/total_loss/avg: 9.4249, max mem: 20597.0, experiment: run, epoch: 44, num_updates: 11600, iterations: 11600, max_updates: 24000, lr: 0.0001, ups: 1.09, time: 01m 32s 593ms, time_since_start: 03h 21m 05s 846ms, eta: 03h 18m 49s 316ms
2022-05-06T18:17:34 | INFO | mmf.trainers.callbacks.logistics : progress: 11700/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.0272, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 9.3531, train/total_loss: 1.0272, train/total_loss/avg: 9.3531, max mem: 20597.0, experiment: run, epoch: 44, num_updates: 11700, iterations: 11700, max_updates: 24000, lr: 0.0001, ups: 1.09, time: 01m 32s 244ms, time_since_start: 03h 22m 38s 090ms, eta: 03h 16m 28s 510ms
2022-05-06T18:19:06 | INFO | mmf.trainers.callbacks.logistics : progress: 11800/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.0272, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 9.2828, train/total_loss: 1.0272, train/total_loss/avg: 9.2828, max mem: 20597.0, experiment: run, epoch: 44, num_updates: 11800, iterations: 11800, max_updates: 24000, lr: 0.0001, ups: 1.09, time: 01m 32s 245ms, time_since_start: 03h 24m 10s 335ms, eta: 03h 14m 52s 827ms
2022-05-06T18:20:38 | INFO | mmf.trainers.callbacks.logistics : progress: 11900/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.0194, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 9.2123, train/total_loss: 1.0194, train/total_loss/avg: 9.2123, max mem: 20597.0, experiment: run, epoch: 45, num_updates: 11900, iterations: 11900, max_updates: 24000, lr: 0.0001, ups: 1.10, time: 01m 31s 878ms, time_since_start: 03h 25m 42s 213ms, eta: 03h 12m 30s 861ms
2022-05-06T18:22:11 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-06T18:22:11 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T18:22:13 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T18:22:14 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T18:22:14 | INFO | mmf.trainers.callbacks.logistics : progress: 12000/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.0147, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 9.1425, train/total_loss: 1.0147, train/total_loss/avg: 9.1425, max mem: 20597.0, experiment: run, epoch: 45, num_updates: 12000, iterations: 12000, max_updates: 24000, lr: 0.0001, ups: 1.04, time: 01m 36s 150ms, time_since_start: 03h 27m 18s 364ms, eta: 03h 19m 48s 093ms
2022-05-06T18:22:14 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-06T18:22:14 | INFO | mmf.common.test_reporter : Predicting for modality_hotpot
2022-05-06T18:23:06 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 39
2022-05-06T18:23:06 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-06T18:23:08 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T18:23:12 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T18:23:16 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T18:23:16 | INFO | mmf.trainers.callbacks.logistics : progress: 12000/24000, val/modality_hotpot/m4c_decoding_bce_with_mask: 6.7891, val/total_loss: 6.7891, val/modality_hotpot/textvqa_accuracy: 0.4549, num_updates: 12000, epoch: 45, iterations: 12000, max_updates: 24000, val_time: 01m 02s 242ms, best_update: 9000, best_iteration: 9000, best_val/modality_hotpot/textvqa_accuracy: 0.459460
2022-05-06T18:24:46 | INFO | mmf.trainers.callbacks.logistics : progress: 12100/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.0147, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 9.0748, train/total_loss: 1.0147, train/total_loss/avg: 9.0748, max mem: 20597.0, experiment: run, epoch: 45, num_updates: 12100, iterations: 12100, max_updates: 24000, lr: 0.0001, ups: 1.12, time: 01m 29s 200ms, time_since_start: 03h 29m 49s 808ms, eta: 03h 03m 48s 820ms
2022-05-06T18:26:18 | INFO | mmf.trainers.callbacks.logistics : progress: 12200/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.0125, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 9.0072, train/total_loss: 1.0125, train/total_loss/avg: 9.0072, max mem: 20597.0, experiment: run, epoch: 46, num_updates: 12200, iterations: 12200, max_updates: 24000, lr: 0.0001, ups: 1.09, time: 01m 32s 813ms, time_since_start: 03h 31m 22s 621ms, eta: 03h 09m 39s 062ms
2022-05-06T18:27:51 | INFO | mmf.trainers.callbacks.logistics : progress: 12300/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 1.0125, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 8.9413, train/total_loss: 1.0125, train/total_loss/avg: 8.9413, max mem: 20597.0, experiment: run, epoch: 46, num_updates: 12300, iterations: 12300, max_updates: 24000, lr: 0.0001, ups: 1.09, time: 01m 32s 151ms, time_since_start: 03h 32m 54s 772ms, eta: 03h 06m 42s 158ms
2022-05-06T18:29:25 | INFO | mmf.trainers.callbacks.logistics : progress: 12400/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.9973, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 8.8772, train/total_loss: 0.9973, train/total_loss/avg: 8.8772, max mem: 20597.0, experiment: run, epoch: 47, num_updates: 12400, iterations: 12400, max_updates: 24000, lr: 0.0001, ups: 1.06, time: 01m 34s 000ms, time_since_start: 03h 34m 28s 773ms, eta: 03h 08m 49s 367ms
2022-05-06T18:30:56 | INFO | mmf.trainers.callbacks.logistics : progress: 12500/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.9704, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 8.8133, train/total_loss: 0.9704, train/total_loss/avg: 8.8133, max mem: 20597.0, experiment: run, epoch: 47, num_updates: 12500, iterations: 12500, max_updates: 24000, lr: 0.0001, ups: 1.10, time: 01m 31s 492ms, time_since_start: 03h 36m 266ms, eta: 03h 02m 11s 991ms
2022-05-06T18:32:27 | INFO | mmf.trainers.callbacks.logistics : progress: 12600/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.9470, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 8.7503, train/total_loss: 0.9470, train/total_loss/avg: 8.7503, max mem: 20597.0, experiment: run, epoch: 47, num_updates: 12600, iterations: 12600, max_updates: 24000, lr: 0.0001, ups: 1.11, time: 01m 30s 718ms, time_since_start: 03h 37m 30s 984ms, eta: 02h 59m 05s 245ms
2022-05-06T18:34:01 | INFO | mmf.trainers.callbacks.logistics : progress: 12700/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.9460, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 8.6876, train/total_loss: 0.9460, train/total_loss/avg: 8.6876, max mem: 20597.0, experiment: run, epoch: 48, num_updates: 12700, iterations: 12700, max_updates: 24000, lr: 0.0001, ups: 1.06, time: 01m 34s 667ms, time_since_start: 03h 39m 05s 651ms, eta: 03h 05m 14s 573ms
2022-05-06T18:35:34 | INFO | mmf.trainers.callbacks.logistics : progress: 12800/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.9238, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 8.6269, train/total_loss: 0.9238, train/total_loss/avg: 8.6269, max mem: 20597.0, experiment: run, epoch: 48, num_updates: 12800, iterations: 12800, max_updates: 24000, lr: 0.0001, ups: 1.09, time: 01m 32s 113ms, time_since_start: 03h 40m 37s 765ms, eta: 02h 58m 39s 108ms
2022-05-06T18:37:06 | INFO | mmf.trainers.callbacks.logistics : progress: 12900/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.9238, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 8.5680, train/total_loss: 0.9238, train/total_loss/avg: 8.5680, max mem: 20597.0, experiment: run, epoch: 48, num_updates: 12900, iterations: 12900, max_updates: 24000, lr: 0.0001, ups: 1.09, time: 01m 32s 353ms, time_since_start: 03h 42m 10s 118ms, eta: 02h 57m 30s 997ms
2022-05-06T18:38:37 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-06T18:38:37 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T18:38:38 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T18:38:43 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T18:38:43 | INFO | mmf.trainers.callbacks.logistics : progress: 13000/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.9460, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 8.5094, train/total_loss: 0.9460, train/total_loss/avg: 8.5094, max mem: 20597.0, experiment: run, epoch: 49, num_updates: 13000, iterations: 13000, max_updates: 24000, lr: 0.0001, ups: 1.03, time: 01m 37s 545ms, time_since_start: 03h 43m 47s 663ms, eta: 03h 05m 48s 434ms
2022-05-06T18:38:43 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-06T18:38:43 | INFO | mmf.common.test_reporter : Predicting for modality_hotpot
2022-05-06T18:39:36 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 39
2022-05-06T18:39:36 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-06T18:39:38 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T18:39:42 | INFO | mmf.utils.checkpoint : Saving best checkpoint
2022-05-06T18:39:47 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T18:39:51 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T18:39:51 | INFO | mmf.trainers.callbacks.logistics : progress: 13000/24000, val/modality_hotpot/m4c_decoding_bce_with_mask: 6.9483, val/total_loss: 6.9483, val/modality_hotpot/textvqa_accuracy: 0.4634, num_updates: 13000, epoch: 49, iterations: 13000, max_updates: 24000, val_time: 01m 08s 015ms, best_update: 13000, best_iteration: 13000, best_val/modality_hotpot/textvqa_accuracy: 0.463400
2022-05-06T18:41:23 | INFO | mmf.trainers.callbacks.logistics : progress: 13100/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.9460, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 8.4521, train/total_loss: 0.9460, train/total_loss/avg: 8.4521, max mem: 20597.0, experiment: run, epoch: 49, num_updates: 13100, iterations: 13100, max_updates: 24000, lr: 0.0001, ups: 1.10, time: 01m 31s 505ms, time_since_start: 03h 46m 27s 185ms, eta: 02h 52m 43s 060ms
2022-05-06T18:42:55 | INFO | mmf.trainers.callbacks.logistics : progress: 13200/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.9460, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 8.3962, train/total_loss: 0.9460, train/total_loss/avg: 8.3962, max mem: 20597.0, experiment: run, epoch: 50, num_updates: 13200, iterations: 13200, max_updates: 24000, lr: 0.0001, ups: 1.09, time: 01m 32s 230ms, time_since_start: 03h 47m 59s 416ms, eta: 02h 52m 29s 371ms
2022-05-06T18:44:27 | INFO | mmf.trainers.callbacks.logistics : progress: 13300/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.9238, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 8.3399, train/total_loss: 0.9238, train/total_loss/avg: 8.3399, max mem: 20597.0, experiment: run, epoch: 50, num_updates: 13300, iterations: 13300, max_updates: 24000, lr: 0.0001, ups: 1.10, time: 01m 31s 443ms, time_since_start: 03h 49m 30s 860ms, eta: 02h 49m 26s 091ms
2022-05-06T18:46:03 | INFO | mmf.trainers.callbacks.logistics : progress: 13400/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.9238, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 8.2864, train/total_loss: 0.9238, train/total_loss/avg: 8.2864, max mem: 20597.0, experiment: run, epoch: 50, num_updates: 13400, iterations: 13400, max_updates: 24000, lr: 0.0001, ups: 1.04, time: 01m 36s 115ms, time_since_start: 03h 51m 06s 975ms, eta: 02h 56m 25s 555ms
2022-05-06T18:47:36 | INFO | mmf.trainers.callbacks.logistics : progress: 13500/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.9238, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 8.2332, train/total_loss: 0.9238, train/total_loss/avg: 8.2332, max mem: 20597.0, experiment: run, epoch: 51, num_updates: 13500, iterations: 13500, max_updates: 24000, lr: 0.0001, ups: 1.08, time: 01m 33s 417ms, time_since_start: 03h 52m 40s 393ms, eta: 02h 49m 51s 388ms
2022-05-06T18:49:07 | INFO | mmf.trainers.callbacks.logistics : progress: 13600/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.9238, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 8.1790, train/total_loss: 0.9238, train/total_loss/avg: 8.1790, max mem: 20597.0, experiment: run, epoch: 51, num_updates: 13600, iterations: 13600, max_updates: 24000, lr: 0.0001, ups: 1.10, time: 01m 31s 014ms, time_since_start: 03h 54m 11s 407ms, eta: 02h 43m 54s 672ms
2022-05-06T18:50:40 | INFO | mmf.trainers.callbacks.logistics : progress: 13700/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.9238, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 8.1271, train/total_loss: 0.9238, train/total_loss/avg: 8.1271, max mem: 20597.0, experiment: run, epoch: 51, num_updates: 13700, iterations: 13700, max_updates: 24000, lr: 0.0001, ups: 1.09, time: 01m 32s 442ms, time_since_start: 03h 55m 43s 850ms, eta: 02h 44m 52s 962ms
2022-05-06T18:52:17 | INFO | mmf.trainers.callbacks.logistics : progress: 13800/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.9108, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 8.0741, train/total_loss: 0.9108, train/total_loss/avg: 8.0741, max mem: 20597.0, experiment: run, epoch: 52, num_updates: 13800, iterations: 13800, max_updates: 24000, lr: 0.0001, ups: 1.03, time: 01m 37s 013ms, time_since_start: 03h 57m 20s 863ms, eta: 02h 51m 21s 254ms
2022-05-06T18:53:52 | INFO | mmf.trainers.callbacks.logistics : progress: 13900/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.9238, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 8.0228, train/total_loss: 0.9238, train/total_loss/avg: 8.0228, max mem: 20597.0, experiment: run, epoch: 52, num_updates: 13900, iterations: 13900, max_updates: 24000, lr: 0.0001, ups: 1.06, time: 01m 34s 906ms, time_since_start: 03h 58m 55s 770ms, eta: 02h 45m 59s 414ms
2022-05-06T18:55:26 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-06T18:55:26 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T18:55:27 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T18:55:32 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T18:55:32 | INFO | mmf.trainers.callbacks.logistics : progress: 14000/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.9337, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 7.9723, train/total_loss: 0.9337, train/total_loss/avg: 7.9723, max mem: 20597.0, experiment: run, epoch: 53, num_updates: 14000, iterations: 14000, max_updates: 24000, lr: 0.00001, ups: 1.00, time: 01m 40s 440ms, time_since_start: 04h 36s 211ms, eta: 02h 53m 55s 791ms
2022-05-06T18:55:32 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-06T18:55:32 | INFO | mmf.common.test_reporter : Predicting for modality_hotpot
2022-05-06T18:56:25 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 39
2022-05-06T18:56:25 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-06T18:56:27 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T18:56:31 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T18:56:36 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T18:56:36 | INFO | mmf.trainers.callbacks.logistics : progress: 14000/24000, val/modality_hotpot/m4c_decoding_bce_with_mask: 7.0894, val/total_loss: 7.0894, val/modality_hotpot/textvqa_accuracy: 0.4619, num_updates: 14000, epoch: 53, iterations: 14000, max_updates: 24000, val_time: 01m 04s 095ms, best_update: 13000, best_iteration: 13000, best_val/modality_hotpot/textvqa_accuracy: 0.463400
2022-05-06T18:58:06 | INFO | mmf.trainers.callbacks.logistics : progress: 14100/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.9238, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 7.9214, train/total_loss: 0.9238, train/total_loss/avg: 7.9214, max mem: 20597.0, experiment: run, epoch: 53, num_updates: 14100, iterations: 14100, max_updates: 24000, lr: 0.00001, ups: 1.12, time: 01m 29s 887ms, time_since_start: 04h 03m 10s 195ms, eta: 02h 34m 05s 971ms
2022-05-06T18:59:38 | INFO | mmf.trainers.callbacks.logistics : progress: 14200/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.9238, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 7.8720, train/total_loss: 0.9238, train/total_loss/avg: 7.8720, max mem: 20597.0, experiment: run, epoch: 53, num_updates: 14200, iterations: 14200, max_updates: 24000, lr: 0.00001, ups: 1.09, time: 01m 32s 362ms, time_since_start: 04h 04m 42s 557ms, eta: 02h 36m 44s 492ms
2022-05-06T19:01:12 | INFO | mmf.trainers.callbacks.logistics : progress: 14300/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.9238, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 7.8229, train/total_loss: 0.9238, train/total_loss/avg: 7.8229, max mem: 20597.0, experiment: run, epoch: 54, num_updates: 14300, iterations: 14300, max_updates: 24000, lr: 0.00001, ups: 1.08, time: 01m 33s 498ms, time_since_start: 04h 06m 16s 055ms, eta: 02h 37m 03s 013ms
2022-05-06T19:02:45 | INFO | mmf.trainers.callbacks.logistics : progress: 14400/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.9122, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 7.7742, train/total_loss: 0.9122, train/total_loss/avg: 7.7742, max mem: 20597.0, experiment: run, epoch: 54, num_updates: 14400, iterations: 14400, max_updates: 24000, lr: 0.00001, ups: 1.09, time: 01m 32s 747ms, time_since_start: 04h 07m 48s 803ms, eta: 02h 34m 11s 006ms
2022-05-06T19:04:16 | INFO | mmf.trainers.callbacks.logistics : progress: 14500/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.9122, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 7.7257, train/total_loss: 0.9122, train/total_loss/avg: 7.7257, max mem: 20597.0, experiment: run, epoch: 54, num_updates: 14500, iterations: 14500, max_updates: 24000, lr: 0.00001, ups: 1.10, time: 01m 31s 445ms, time_since_start: 04h 09m 20s 248ms, eta: 02h 30m 26s 120ms
2022-05-06T19:05:49 | INFO | mmf.trainers.callbacks.logistics : progress: 14600/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.9122, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 7.6777, train/total_loss: 0.9122, train/total_loss/avg: 7.6777, max mem: 20597.0, experiment: run, epoch: 55, num_updates: 14600, iterations: 14600, max_updates: 24000, lr: 0.00001, ups: 1.08, time: 01m 33s 013ms, time_since_start: 04h 10m 53s 262ms, eta: 02h 31m 24s 301ms
2022-05-06T19:07:19 | INFO | mmf.trainers.callbacks.logistics : progress: 14700/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.9122, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 7.6316, train/total_loss: 0.9122, train/total_loss/avg: 7.6316, max mem: 20597.0, experiment: run, epoch: 55, num_updates: 14700, iterations: 14700, max_updates: 24000, lr: 0.00001, ups: 1.12, time: 01m 29s 664ms, time_since_start: 04h 12m 22s 927ms, eta: 02h 24m 24s 035ms
2022-05-06T19:08:55 | INFO | mmf.trainers.callbacks.logistics : progress: 14800/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.9108, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 7.5858, train/total_loss: 0.9108, train/total_loss/avg: 7.5858, max mem: 20597.0, experiment: run, epoch: 56, num_updates: 14800, iterations: 14800, max_updates: 24000, lr: 0.00001, ups: 1.04, time: 01m 36s 149ms, time_since_start: 04h 13m 59s 077ms, eta: 02h 33m 10s 747ms
2022-05-06T19:10:25 | INFO | mmf.trainers.callbacks.logistics : progress: 14900/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.9095, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 7.5409, train/total_loss: 0.9095, train/total_loss/avg: 7.5409, max mem: 20597.0, experiment: run, epoch: 56, num_updates: 14900, iterations: 14900, max_updates: 24000, lr: 0.00001, ups: 1.11, time: 01m 30s 525ms, time_since_start: 04h 15m 29s 602ms, eta: 02h 22m 39s 061ms
2022-05-06T19:11:55 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-06T19:11:55 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T19:11:56 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T19:12:00 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T19:12:00 | INFO | mmf.trainers.callbacks.logistics : progress: 15000/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.9095, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 7.4968, train/total_loss: 0.9095, train/total_loss/avg: 7.4968, max mem: 20597.0, experiment: run, epoch: 56, num_updates: 15000, iterations: 15000, max_updates: 24000, lr: 0.00001, ups: 1.06, time: 01m 34s 797ms, time_since_start: 04h 17m 04s 399ms, eta: 02h 27m 44s 499ms
2022-05-06T19:12:00 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-06T19:12:00 | INFO | mmf.common.test_reporter : Predicting for modality_hotpot
2022-05-06T19:12:53 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 39
2022-05-06T19:12:53 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-06T19:12:55 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T19:13:00 | INFO | mmf.utils.checkpoint : Saving best checkpoint
2022-05-06T19:13:05 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T19:13:09 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T19:13:09 | INFO | mmf.trainers.callbacks.logistics : progress: 15000/24000, val/modality_hotpot/m4c_decoding_bce_with_mask: 7.0653, val/total_loss: 7.0653, val/modality_hotpot/textvqa_accuracy: 0.4679, num_updates: 15000, epoch: 56, iterations: 15000, max_updates: 24000, val_time: 01m 09s 215ms, best_update: 15000, best_iteration: 15000, best_val/modality_hotpot/textvqa_accuracy: 0.467940
2022-05-06T19:14:41 | INFO | mmf.trainers.callbacks.logistics : progress: 15100/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.8936, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 7.4518, train/total_loss: 0.8936, train/total_loss/avg: 7.4518, max mem: 20597.0, experiment: run, epoch: 57, num_updates: 15100, iterations: 15100, max_updates: 24000, lr: 0.00001, ups: 1.10, time: 01m 31s 636ms, time_since_start: 04h 19m 45s 252ms, eta: 02h 21m 13s 731ms
2022-05-06T19:16:13 | INFO | mmf.trainers.callbacks.logistics : progress: 15200/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.8566, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 7.4083, train/total_loss: 0.8566, train/total_loss/avg: 7.4083, max mem: 20597.0, experiment: run, epoch: 57, num_updates: 15200, iterations: 15200, max_updates: 24000, lr: 0.00001, ups: 1.10, time: 01m 31s 685ms, time_since_start: 04h 21m 16s 938ms, eta: 02h 19m 42s 982ms
2022-05-06T19:17:43 | INFO | mmf.trainers.callbacks.logistics : progress: 15300/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.8514, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 7.3650, train/total_loss: 0.8514, train/total_loss/avg: 7.3650, max mem: 20597.0, experiment: run, epoch: 57, num_updates: 15300, iterations: 15300, max_updates: 24000, lr: 0.00001, ups: 1.12, time: 01m 29s 968ms, time_since_start: 04h 22m 46s 906ms, eta: 02h 15m 32s 486ms
2022-05-06T19:19:19 | INFO | mmf.trainers.callbacks.logistics : progress: 15400/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.8434, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 7.3222, train/total_loss: 0.8434, train/total_loss/avg: 7.3222, max mem: 20597.0, experiment: run, epoch: 58, num_updates: 15400, iterations: 15400, max_updates: 24000, lr: 0.00001, ups: 1.04, time: 01m 36s 068ms, time_since_start: 04h 24m 22s 974ms, eta: 02h 23m 04s 077ms
2022-05-06T19:20:49 | INFO | mmf.trainers.callbacks.logistics : progress: 15500/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.8362, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 7.2798, train/total_loss: 0.8362, train/total_loss/avg: 7.2798, max mem: 20597.0, experiment: run, epoch: 58, num_updates: 15500, iterations: 15500, max_updates: 24000, lr: 0.00001, ups: 1.11, time: 01m 30s 097ms, time_since_start: 04h 25m 53s 071ms, eta: 02h 12m 36s 936ms
2022-05-06T19:22:21 | INFO | mmf.trainers.callbacks.logistics : progress: 15600/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.8129, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 7.2382, train/total_loss: 0.8129, train/total_loss/avg: 7.2382, max mem: 20597.0, experiment: run, epoch: 58, num_updates: 15600, iterations: 15600, max_updates: 24000, lr: 0.00001, ups: 1.09, time: 01m 32s 404ms, time_since_start: 04h 27m 25s 476ms, eta: 02h 14m 24s 690ms
2022-05-06T19:23:58 | INFO | mmf.trainers.callbacks.logistics : progress: 15700/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.8074, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 7.1965, train/total_loss: 0.8074, train/total_loss/avg: 7.1965, max mem: 20597.0, experiment: run, epoch: 59, num_updates: 15700, iterations: 15700, max_updates: 24000, lr: 0.00001, ups: 1.04, time: 01m 36s 913ms, time_since_start: 04h 29m 02s 390ms, eta: 02h 19m 17s 558ms
2022-05-06T19:25:31 | INFO | mmf.trainers.callbacks.logistics : progress: 15800/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7939, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 7.1557, train/total_loss: 0.7939, train/total_loss/avg: 7.1557, max mem: 20597.0, experiment: run, epoch: 59, num_updates: 15800, iterations: 15800, max_updates: 24000, lr: 0.00001, ups: 1.09, time: 01m 32s 856ms, time_since_start: 04h 30m 35s 246ms, eta: 02h 11m 51s 195ms
2022-05-06T19:27:10 | INFO | mmf.trainers.callbacks.logistics : progress: 15900/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7939, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 7.1157, train/total_loss: 0.7939, train/total_loss/avg: 7.1157, max mem: 20597.0, experiment: run, epoch: 60, num_updates: 15900, iterations: 15900, max_updates: 24000, lr: 0.00001, ups: 1.01, time: 01m 39s 193ms, time_since_start: 04h 32m 14s 440ms, eta: 02h 19m 08s 029ms
2022-05-06T19:28:42 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-06T19:28:42 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T19:28:43 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T19:28:48 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T19:28:48 | INFO | mmf.trainers.callbacks.logistics : progress: 16000/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7881, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 7.0755, train/total_loss: 0.7881, train/total_loss/avg: 7.0755, max mem: 20597.0, experiment: run, epoch: 60, num_updates: 16000, iterations: 16000, max_updates: 24000, lr: 0.00001, ups: 1.03, time: 01m 37s 309ms, time_since_start: 04h 33m 51s 749ms, eta: 02h 14m 48s 335ms
2022-05-06T19:28:48 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-06T19:28:48 | INFO | mmf.common.test_reporter : Predicting for modality_hotpot
2022-05-06T19:29:40 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 39
2022-05-06T19:29:40 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-06T19:29:42 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T19:29:46 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T19:29:51 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T19:29:51 | INFO | mmf.trainers.callbacks.logistics : progress: 16000/24000, val/modality_hotpot/m4c_decoding_bce_with_mask: 7.0750, val/total_loss: 7.0750, val/modality_hotpot/textvqa_accuracy: 0.4674, num_updates: 16000, epoch: 60, iterations: 16000, max_updates: 24000, val_time: 01m 03s 339ms, best_update: 15000, best_iteration: 15000, best_val/modality_hotpot/textvqa_accuracy: 0.467940
2022-05-06T19:31:18 | INFO | mmf.trainers.callbacks.logistics : progress: 16100/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7939, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 7.0369, train/total_loss: 0.7939, train/total_loss/avg: 7.0369, max mem: 20597.0, experiment: run, epoch: 60, num_updates: 16100, iterations: 16100, max_updates: 24000, lr: 0.00001, ups: 1.15, time: 01m 27s 011ms, time_since_start: 04h 36m 22s 102ms, eta: 01h 59m 02s 021ms
2022-05-06T19:32:51 | INFO | mmf.trainers.callbacks.logistics : progress: 16200/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7809, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 6.9976, train/total_loss: 0.7809, train/total_loss/avg: 6.9976, max mem: 20597.0, experiment: run, epoch: 61, num_updates: 16200, iterations: 16200, max_updates: 24000, lr: 0.00001, ups: 1.08, time: 01m 33s 167ms, time_since_start: 04h 37m 55s 270ms, eta: 02h 05m 50s 501ms
2022-05-06T19:34:23 | INFO | mmf.trainers.callbacks.logistics : progress: 16300/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7741, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 6.9590, train/total_loss: 0.7741, train/total_loss/avg: 6.9590, max mem: 20597.0, experiment: run, epoch: 61, num_updates: 16300, iterations: 16300, max_updates: 24000, lr: 0.00001, ups: 1.09, time: 01m 32s 075ms, time_since_start: 04h 39m 27s 346ms, eta: 02h 02m 46s 353ms
2022-05-06T19:35:55 | INFO | mmf.trainers.callbacks.logistics : progress: 16400/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7741, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 6.9215, train/total_loss: 0.7741, train/total_loss/avg: 6.9215, max mem: 20597.0, experiment: run, epoch: 61, num_updates: 16400, iterations: 16400, max_updates: 24000, lr: 0.00001, ups: 1.09, time: 01m 32s 067ms, time_since_start: 04h 40m 59s 413ms, eta: 02h 01m 09s 997ms
2022-05-06T19:37:29 | INFO | mmf.trainers.callbacks.logistics : progress: 16500/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7741, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 6.8835, train/total_loss: 0.7741, train/total_loss/avg: 6.8835, max mem: 20597.0, experiment: run, epoch: 62, num_updates: 16500, iterations: 16500, max_updates: 24000, lr: 0.00001, ups: 1.08, time: 01m 33s 629ms, time_since_start: 04h 42m 33s 043ms, eta: 02h 01m 36s 070ms
2022-05-06T19:39:01 | INFO | mmf.trainers.callbacks.logistics : progress: 16600/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7741, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 6.8463, train/total_loss: 0.7741, train/total_loss/avg: 6.8463, max mem: 20597.0, experiment: run, epoch: 62, num_updates: 16600, iterations: 16600, max_updates: 24000, lr: 0.00001, ups: 1.09, time: 01m 32s 077ms, time_since_start: 04h 44m 05s 120ms, eta: 01h 57m 59s 451ms
2022-05-06T19:40:37 | INFO | mmf.trainers.callbacks.logistics : progress: 16700/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7549, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 6.8096, train/total_loss: 0.7549, train/total_loss/avg: 6.8096, max mem: 20597.0, experiment: run, epoch: 63, num_updates: 16700, iterations: 16700, max_updates: 24000, lr: 0.00001, ups: 1.05, time: 01m 35s 711ms, time_since_start: 04h 45m 40s 832ms, eta: 02h 59s 469ms
2022-05-06T19:42:09 | INFO | mmf.trainers.callbacks.logistics : progress: 16800/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7455, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 6.7731, train/total_loss: 0.7455, train/total_loss/avg: 6.7731, max mem: 20597.0, experiment: run, epoch: 63, num_updates: 16800, iterations: 16800, max_updates: 24000, lr: 0.00001, ups: 1.09, time: 01m 32s 016ms, time_since_start: 04h 47m 12s 849ms, eta: 01h 54m 43s 600ms
2022-05-06T19:43:39 | INFO | mmf.trainers.callbacks.logistics : progress: 16900/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7455, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 6.7379, train/total_loss: 0.7455, train/total_loss/avg: 6.7379, max mem: 20597.0, experiment: run, epoch: 63, num_updates: 16900, iterations: 16900, max_updates: 24000, lr: 0.00001, ups: 1.11, time: 01m 30s 644ms, time_since_start: 04h 48m 43s 493ms, eta: 01h 51m 26s 765ms
2022-05-06T19:45:14 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-06T19:45:14 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T19:45:16 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T19:45:20 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T19:45:20 | INFO | mmf.trainers.callbacks.logistics : progress: 17000/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7225, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 6.7018, train/total_loss: 0.7225, train/total_loss/avg: 6.7018, max mem: 20597.0, experiment: run, epoch: 64, num_updates: 17000, iterations: 17000, max_updates: 24000, lr: 0.00001, ups: 0.99, time: 01m 41s 115ms, time_since_start: 04h 50m 24s 609ms, eta: 02h 02m 34s 166ms
2022-05-06T19:45:20 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-06T19:45:20 | INFO | mmf.common.test_reporter : Predicting for modality_hotpot
2022-05-06T19:46:13 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 39
2022-05-06T19:46:13 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-06T19:46:15 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T19:46:20 | INFO | mmf.utils.checkpoint : Saving best checkpoint
2022-05-06T19:46:24 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T19:46:29 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T19:46:29 | INFO | mmf.trainers.callbacks.logistics : progress: 17000/24000, val/modality_hotpot/m4c_decoding_bce_with_mask: 7.1351, val/total_loss: 7.1351, val/modality_hotpot/textvqa_accuracy: 0.4727, num_updates: 17000, epoch: 64, iterations: 17000, max_updates: 24000, val_time: 01m 08s 452ms, best_update: 17000, best_iteration: 17000, best_val/modality_hotpot/textvqa_accuracy: 0.472720
2022-05-06T19:47:59 | INFO | mmf.trainers.callbacks.logistics : progress: 17100/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7455, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 6.6675, train/total_loss: 0.7455, train/total_loss/avg: 6.6675, max mem: 20597.0, experiment: run, epoch: 64, num_updates: 17100, iterations: 17100, max_updates: 24000, lr: 0.00001, ups: 1.12, time: 01m 29s 794ms, time_since_start: 04h 53m 02s 858ms, eta: 01h 47m 17s 469ms
2022-05-06T19:49:35 | INFO | mmf.trainers.callbacks.logistics : progress: 17200/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7455, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 6.6334, train/total_loss: 0.7455, train/total_loss/avg: 6.6334, max mem: 20597.0, experiment: run, epoch: 64, num_updates: 17200, iterations: 17200, max_updates: 24000, lr: 0.00001, ups: 1.04, time: 01m 36s 251ms, time_since_start: 04h 54m 39s 109ms, eta: 01h 53m 20s 336ms
2022-05-06T19:51:12 | INFO | mmf.trainers.callbacks.logistics : progress: 17300/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7455, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 6.5998, train/total_loss: 0.7455, train/total_loss/avg: 6.5998, max mem: 20597.0, experiment: run, epoch: 65, num_updates: 17300, iterations: 17300, max_updates: 24000, lr: 0.00001, ups: 1.03, time: 01m 37s 341ms, time_since_start: 04h 56m 16s 451ms, eta: 01h 52m 56s 200ms
2022-05-06T19:52:42 | INFO | mmf.trainers.callbacks.logistics : progress: 17400/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7455, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 6.5662, train/total_loss: 0.7455, train/total_loss/avg: 6.5662, max mem: 20597.0, experiment: run, epoch: 65, num_updates: 17400, iterations: 17400, max_updates: 24000, lr: 0.00001, ups: 1.12, time: 01m 29s 592ms, time_since_start: 04h 57m 46s 043ms, eta: 01h 42m 23s 746ms
2022-05-06T19:54:15 | INFO | mmf.trainers.callbacks.logistics : progress: 17500/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7455, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 6.5331, train/total_loss: 0.7455, train/total_loss/avg: 6.5331, max mem: 20597.0, experiment: run, epoch: 66, num_updates: 17500, iterations: 17500, max_updates: 24000, lr: 0.00001, ups: 1.09, time: 01m 32s 920ms, time_since_start: 04h 59m 18s 964ms, eta: 01h 44m 35s 365ms
2022-05-06T19:55:47 | INFO | mmf.trainers.callbacks.logistics : progress: 17600/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7225, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 6.4995, train/total_loss: 0.7225, train/total_loss/avg: 6.4995, max mem: 20597.0, experiment: run, epoch: 66, num_updates: 17600, iterations: 17600, max_updates: 24000, lr: 0.00001, ups: 1.09, time: 01m 32s 101ms, time_since_start: 05h 51s 065ms, eta: 01h 42m 04s 372ms
2022-05-06T19:57:18 | INFO | mmf.trainers.callbacks.logistics : progress: 17700/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7225, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 6.4665, train/total_loss: 0.7225, train/total_loss/avg: 6.4665, max mem: 20597.0, experiment: run, epoch: 66, num_updates: 17700, iterations: 17700, max_updates: 24000, lr: 0.00001, ups: 1.11, time: 01m 30s 736ms, time_since_start: 05h 02m 21s 802ms, eta: 01h 38m 59s 336ms
2022-05-06T19:58:51 | INFO | mmf.trainers.callbacks.logistics : progress: 17800/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7225, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 6.4347, train/total_loss: 0.7225, train/total_loss/avg: 6.4347, max mem: 20597.0, experiment: run, epoch: 67, num_updates: 17800, iterations: 17800, max_updates: 24000, lr: 0.00001, ups: 1.08, time: 01m 33s 730ms, time_since_start: 05h 03m 55s 532ms, eta: 01h 40m 37s 952ms
2022-05-06T20:00:32 | INFO | mmf.trainers.callbacks.logistics : progress: 17900/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7056, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 6.4027, train/total_loss: 0.7056, train/total_loss/avg: 6.4027, max mem: 20597.0, experiment: run, epoch: 67, num_updates: 17900, iterations: 17900, max_updates: 24000, lr: 0.00001, ups: 1.00, time: 01m 40s 347ms, time_since_start: 05h 05m 35s 880ms, eta: 01h 45m 59s 922ms
2022-05-06T20:02:29 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-06T20:02:29 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T20:02:30 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T20:02:36 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T20:02:36 | INFO | mmf.trainers.callbacks.logistics : progress: 18000/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7056, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 6.3710, train/total_loss: 0.7056, train/total_loss/avg: 6.3710, max mem: 20597.0, experiment: run, epoch: 67, num_updates: 18000, iterations: 18000, max_updates: 24000, lr: 0.00001, ups: 0.81, time: 02m 04s 024ms, time_since_start: 05h 07m 39s 904ms, eta: 02h 08m 51s 676ms
2022-05-06T20:02:36 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-06T20:02:36 | INFO | mmf.common.test_reporter : Predicting for modality_hotpot
2022-05-06T20:04:23 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 39
2022-05-06T20:04:23 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-06T20:04:25 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T20:04:30 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T20:04:34 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T20:04:34 | INFO | mmf.trainers.callbacks.logistics : progress: 18000/24000, val/modality_hotpot/m4c_decoding_bce_with_mask: 7.1346, val/total_loss: 7.1346, val/modality_hotpot/textvqa_accuracy: 0.4695, num_updates: 18000, epoch: 67, iterations: 18000, max_updates: 24000, val_time: 01m 58s 709ms, best_update: 17000, best_iteration: 17000, best_val/modality_hotpot/textvqa_accuracy: 0.472720
2022-05-06T20:06:32 | INFO | mmf.trainers.callbacks.logistics : progress: 18100/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7054, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 6.3392, train/total_loss: 0.7054, train/total_loss/avg: 6.3392, max mem: 20597.0, experiment: run, epoch: 68, num_updates: 18100, iterations: 18100, max_updates: 24000, lr: 0.00001, ups: 0.85, time: 01m 57s 444ms, time_since_start: 05h 11m 36s 063ms, eta: 01h 59m 59s 447ms
2022-05-06T20:08:30 | INFO | mmf.trainers.callbacks.logistics : progress: 18200/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7054, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 6.3083, train/total_loss: 0.7054, train/total_loss/avg: 6.3083, max mem: 20597.0, experiment: run, epoch: 68, num_updates: 18200, iterations: 18200, max_updates: 24000, lr: 0.00001, ups: 0.85, time: 01m 58s 549ms, time_since_start: 05h 13m 34s 613ms, eta: 01h 59m 04s 040ms
2022-05-06T20:10:12 | INFO | mmf.trainers.callbacks.logistics : progress: 18300/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7047, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 6.2773, train/total_loss: 0.7047, train/total_loss/avg: 6.2773, max mem: 20597.0, experiment: run, epoch: 69, num_updates: 18300, iterations: 18300, max_updates: 24000, lr: 0.00001, ups: 0.99, time: 01m 41s 630ms, time_since_start: 05h 15m 16s 243ms, eta: 01h 40m 18s 861ms
2022-05-06T20:11:47 | INFO | mmf.trainers.callbacks.logistics : progress: 18400/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.6975, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 6.2466, train/total_loss: 0.6975, train/total_loss/avg: 6.2466, max mem: 20597.0, experiment: run, epoch: 69, num_updates: 18400, iterations: 18400, max_updates: 24000, lr: 0.00001, ups: 1.05, time: 01m 35s 006ms, time_since_start: 05h 16m 51s 250ms, eta: 01h 32m 07s 854ms
2022-05-06T20:13:44 | INFO | mmf.trainers.callbacks.logistics : progress: 18500/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.6975, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 6.2163, train/total_loss: 0.6975, train/total_loss/avg: 6.2163, max mem: 20597.0, experiment: run, epoch: 69, num_updates: 18500, iterations: 18500, max_updates: 24000, lr: 0.00001, ups: 0.86, time: 01m 56s 851ms, time_since_start: 05h 18m 48s 101ms, eta: 01h 51m 17s 452ms
2022-05-06T20:15:42 | INFO | mmf.trainers.callbacks.logistics : progress: 18600/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7047, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 6.1868, train/total_loss: 0.7047, train/total_loss/avg: 6.1868, max mem: 20597.0, experiment: run, epoch: 70, num_updates: 18600, iterations: 18600, max_updates: 24000, lr: 0.00001, ups: 0.85, time: 01m 57s 698ms, time_since_start: 05h 20m 45s 799ms, eta: 01h 50m 03s 582ms
2022-05-06T20:17:39 | INFO | mmf.trainers.callbacks.logistics : progress: 18700/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7047, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 6.1576, train/total_loss: 0.7047, train/total_loss/avg: 6.1576, max mem: 20597.0, experiment: run, epoch: 70, num_updates: 18700, iterations: 18700, max_updates: 24000, lr: 0.00001, ups: 0.85, time: 01m 57s 846ms, time_since_start: 05h 22m 43s 646ms, eta: 01h 48m 09s 479ms
2022-05-06T20:19:37 | INFO | mmf.trainers.callbacks.logistics : progress: 18800/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7047, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 6.1280, train/total_loss: 0.7047, train/total_loss/avg: 6.1280, max mem: 20597.0, experiment: run, epoch: 70, num_updates: 18800, iterations: 18800, max_updates: 24000, lr: 0.00001, ups: 0.85, time: 01m 57s 431ms, time_since_start: 05h 24m 41s 078ms, eta: 01h 45m 44s 605ms
2022-05-06T20:21:36 | INFO | mmf.trainers.callbacks.logistics : progress: 18900/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7047, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 6.0995, train/total_loss: 0.7047, train/total_loss/avg: 6.0995, max mem: 20597.0, experiment: run, epoch: 71, num_updates: 18900, iterations: 18900, max_updates: 24000, lr: 0.00001, ups: 0.85, time: 01m 58s 821ms, time_since_start: 05h 26m 39s 900ms, eta: 01h 44m 56s 232ms
2022-05-06T20:23:08 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-06T20:23:08 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T20:23:10 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T20:23:14 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T20:23:14 | INFO | mmf.trainers.callbacks.logistics : progress: 19000/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7047, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 6.0710, train/total_loss: 0.7047, train/total_loss/avg: 6.0710, max mem: 20597.0, experiment: run, epoch: 71, num_updates: 19000, iterations: 19000, max_updates: 24000, lr: 0., ups: 1.02, time: 01m 38s 423ms, time_since_start: 05h 28m 18s 324ms, eta: 01h 25m 13s 119ms
2022-05-06T20:23:14 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-06T20:23:14 | INFO | mmf.common.test_reporter : Predicting for modality_hotpot
2022-05-06T20:24:06 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 39
2022-05-06T20:24:06 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-06T20:24:08 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T20:24:12 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T20:24:17 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T20:24:17 | INFO | mmf.trainers.callbacks.logistics : progress: 19000/24000, val/modality_hotpot/m4c_decoding_bce_with_mask: 7.3527, val/total_loss: 7.3527, val/modality_hotpot/textvqa_accuracy: 0.4711, num_updates: 19000, epoch: 71, iterations: 19000, max_updates: 24000, val_time: 01m 02s 472ms, best_update: 17000, best_iteration: 17000, best_val/modality_hotpot/textvqa_accuracy: 0.472720
2022-05-06T20:25:49 | INFO | mmf.trainers.callbacks.logistics : progress: 19100/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.6898, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 6.0425, train/total_loss: 0.6898, train/total_loss/avg: 6.0425, max mem: 20597.0, experiment: run, epoch: 72, num_updates: 19100, iterations: 19100, max_updates: 24000, lr: 0., ups: 1.09, time: 01m 32s 280ms, time_since_start: 05h 30m 53s 078ms, eta: 01h 18m 18s 116ms
2022-05-06T20:27:25 | INFO | mmf.trainers.callbacks.logistics : progress: 19200/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.6724, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 6.0144, train/total_loss: 0.6724, train/total_loss/avg: 6.0144, max mem: 20597.0, experiment: run, epoch: 72, num_updates: 19200, iterations: 19200, max_updates: 24000, lr: 0., ups: 1.05, time: 01m 35s 851ms, time_since_start: 05h 32m 28s 930ms, eta: 01h 19m 40s 322ms
2022-05-06T20:28:57 | INFO | mmf.trainers.callbacks.logistics : progress: 19300/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.6633, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.9863, train/total_loss: 0.6633, train/total_loss/avg: 5.9863, max mem: 20597.0, experiment: run, epoch: 72, num_updates: 19300, iterations: 19300, max_updates: 24000, lr: 0., ups: 1.09, time: 01m 32s 720ms, time_since_start: 05h 34m 01s 650ms, eta: 01h 15m 27s 826ms
2022-05-06T20:30:30 | INFO | mmf.trainers.callbacks.logistics : progress: 19400/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.6559, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.9588, train/total_loss: 0.6559, train/total_loss/avg: 5.9588, max mem: 20597.0, experiment: run, epoch: 73, num_updates: 19400, iterations: 19400, max_updates: 24000, lr: 0., ups: 1.09, time: 01m 32s 458ms, time_since_start: 05h 35m 34s 109ms, eta: 01h 13m 38s 951ms
2022-05-06T20:32:03 | INFO | mmf.trainers.callbacks.logistics : progress: 19500/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.6559, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.9318, train/total_loss: 0.6559, train/total_loss/avg: 5.9318, max mem: 20597.0, experiment: run, epoch: 73, num_updates: 19500, iterations: 19500, max_updates: 24000, lr: 0., ups: 1.09, time: 01m 32s 682ms, time_since_start: 05h 37m 06s 792ms, eta: 01h 12m 13s 393ms
2022-05-06T20:33:36 | INFO | mmf.trainers.callbacks.logistics : progress: 19600/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.6633, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.9054, train/total_loss: 0.6633, train/total_loss/avg: 5.9054, max mem: 20597.0, experiment: run, epoch: 73, num_updates: 19600, iterations: 19600, max_updates: 24000, lr: 0., ups: 1.08, time: 01m 33s 317ms, time_since_start: 05h 38m 40s 109ms, eta: 01h 11m 06s 099ms
2022-05-06T20:35:10 | INFO | mmf.trainers.callbacks.logistics : progress: 19700/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.6559, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.8786, train/total_loss: 0.6559, train/total_loss/avg: 5.8786, max mem: 20597.0, experiment: run, epoch: 74, num_updates: 19700, iterations: 19700, max_updates: 24000, lr: 0., ups: 1.08, time: 01m 33s 636ms, time_since_start: 05h 40m 13s 746ms, eta: 01h 09m 43s 407ms
2022-05-06T20:36:42 | INFO | mmf.trainers.callbacks.logistics : progress: 19800/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.6559, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.8527, train/total_loss: 0.6559, train/total_loss/avg: 5.8527, max mem: 20597.0, experiment: run, epoch: 74, num_updates: 19800, iterations: 19800, max_updates: 24000, lr: 0., ups: 1.09, time: 01m 32s 142ms, time_since_start: 05h 41m 45s 888ms, eta: 01h 07m 915ms
2022-05-06T20:38:15 | INFO | mmf.trainers.callbacks.logistics : progress: 19900/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.6559, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.8266, train/total_loss: 0.6559, train/total_loss/avg: 5.8266, max mem: 20597.0, experiment: run, epoch: 74, num_updates: 19900, iterations: 19900, max_updates: 24000, lr: 0., ups: 1.08, time: 01m 33s 234ms, time_since_start: 05h 43m 19s 123ms, eta: 01h 06m 11s 677ms
2022-05-06T20:39:46 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-06T20:39:46 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T20:39:47 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T20:39:52 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T20:39:52 | INFO | mmf.trainers.callbacks.logistics : progress: 20000/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.6559, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.8013, train/total_loss: 0.6559, train/total_loss/avg: 5.8013, max mem: 20597.0, experiment: run, epoch: 75, num_updates: 20000, iterations: 20000, max_updates: 24000, lr: 0., ups: 1.03, time: 01m 37s 073ms, time_since_start: 05h 44m 56s 196ms, eta: 01h 07m 14s 394ms
2022-05-06T20:39:52 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-06T20:39:52 | INFO | mmf.common.test_reporter : Predicting for modality_hotpot
2022-05-06T20:40:43 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 39
2022-05-06T20:40:43 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-06T20:40:45 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T20:40:50 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T20:40:55 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T20:40:55 | INFO | mmf.trainers.callbacks.logistics : progress: 20000/24000, val/modality_hotpot/m4c_decoding_bce_with_mask: 7.4312, val/total_loss: 7.4312, val/modality_hotpot/textvqa_accuracy: 0.4703, num_updates: 20000, epoch: 75, iterations: 20000, max_updates: 24000, val_time: 01m 02s 629ms, best_update: 17000, best_iteration: 17000, best_val/modality_hotpot/textvqa_accuracy: 0.472720
2022-05-06T20:42:25 | INFO | mmf.trainers.callbacks.logistics : progress: 20100/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.6720, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.7760, train/total_loss: 0.6720, train/total_loss/avg: 5.7760, max mem: 20597.0, experiment: run, epoch: 75, num_updates: 20100, iterations: 20100, max_updates: 24000, lr: 0., ups: 1.11, time: 01m 30s 040ms, time_since_start: 05h 47m 28s 867ms, eta: 01h 48s 535ms
2022-05-06T20:44:01 | INFO | mmf.trainers.callbacks.logistics : progress: 20200/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.6720, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.7514, train/total_loss: 0.6720, train/total_loss/avg: 5.7514, max mem: 20597.0, experiment: run, epoch: 76, num_updates: 20200, iterations: 20200, max_updates: 24000, lr: 0., ups: 1.04, time: 01m 36s 626ms, time_since_start: 05h 49m 05s 494ms, eta: 01h 03m 35s 019ms
2022-05-06T20:45:34 | INFO | mmf.trainers.callbacks.logistics : progress: 20300/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.6724, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.7265, train/total_loss: 0.6724, train/total_loss/avg: 5.7265, max mem: 20597.0, experiment: run, epoch: 76, num_updates: 20300, iterations: 20300, max_updates: 24000, lr: 0., ups: 1.09, time: 01m 32s 997ms, time_since_start: 05h 50m 38s 492ms, eta: 59m 35s 093ms
2022-05-06T20:47:06 | INFO | mmf.trainers.callbacks.logistics : progress: 20400/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.6875, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.7028, train/total_loss: 0.6875, train/total_loss/avg: 5.7028, max mem: 20597.0, experiment: run, epoch: 76, num_updates: 20400, iterations: 20400, max_updates: 24000, lr: 0., ups: 1.10, time: 01m 31s 301ms, time_since_start: 05h 52m 09s 793ms, eta: 56m 55s 024ms
2022-05-06T20:48:40 | INFO | mmf.trainers.callbacks.logistics : progress: 20500/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.6889, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.6788, train/total_loss: 0.6889, train/total_loss/avg: 5.6788, max mem: 20597.0, experiment: run, epoch: 77, num_updates: 20500, iterations: 20500, max_updates: 24000, lr: 0., ups: 1.06, time: 01m 34s 041ms, time_since_start: 05h 53m 43s 834ms, eta: 56m 59s 820ms
2022-05-06T20:50:09 | INFO | mmf.trainers.callbacks.logistics : progress: 20600/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.6889, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.6552, train/total_loss: 0.6889, train/total_loss/avg: 5.6552, max mem: 20597.0, experiment: run, epoch: 77, num_updates: 20600, iterations: 20600, max_updates: 24000, lr: 0., ups: 1.12, time: 01m 29s 478ms, time_since_start: 05h 55m 13s 313ms, eta: 52m 40s 935ms
2022-05-06T20:51:40 | INFO | mmf.trainers.callbacks.logistics : progress: 20700/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.6889, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.6321, train/total_loss: 0.6889, train/total_loss/avg: 5.6321, max mem: 20597.0, experiment: run, epoch: 77, num_updates: 20700, iterations: 20700, max_updates: 24000, lr: 0., ups: 1.10, time: 01m 31s 066ms, time_since_start: 05h 56m 44s 380ms, eta: 52m 02s 398ms
2022-05-06T20:53:27 | INFO | mmf.trainers.callbacks.logistics : progress: 20800/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7070, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.6087, train/total_loss: 0.7070, train/total_loss/avg: 5.6087, max mem: 20597.0, experiment: run, epoch: 78, num_updates: 20800, iterations: 20800, max_updates: 24000, lr: 0., ups: 0.93, time: 01m 47s 042ms, time_since_start: 05h 58m 31s 422ms, eta: 59m 18s 944ms
2022-05-06T20:55:20 | INFO | mmf.trainers.callbacks.logistics : progress: 20900/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7070, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.5859, train/total_loss: 0.7070, train/total_loss/avg: 5.5859, max mem: 20597.0, experiment: run, epoch: 78, num_updates: 20900, iterations: 20900, max_updates: 24000, lr: 0., ups: 0.89, time: 01m 52s 946ms, time_since_start: 06h 24s 369ms, eta: 01h 37s 906ms
2022-05-06T20:57:04 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-06T20:57:04 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T20:57:05 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T20:57:10 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T20:57:10 | INFO | mmf.trainers.callbacks.logistics : progress: 21000/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7382, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.5632, train/total_loss: 0.7382, train/total_loss/avg: 5.5632, max mem: 20597.0, experiment: run, epoch: 79, num_updates: 21000, iterations: 21000, max_updates: 24000, lr: 0., ups: 0.92, time: 01m 49s 458ms, time_since_start: 06h 02m 13s 828ms, eta: 56m 51s 831ms
2022-05-06T20:57:10 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-06T20:57:10 | INFO | mmf.common.test_reporter : Predicting for modality_hotpot
2022-05-06T20:58:56 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 39
2022-05-06T20:58:56 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-06T20:58:58 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T20:59:03 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T20:59:07 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T20:59:07 | INFO | mmf.trainers.callbacks.logistics : progress: 21000/24000, val/modality_hotpot/m4c_decoding_bce_with_mask: 7.4052, val/total_loss: 7.4052, val/modality_hotpot/textvqa_accuracy: 0.4708, num_updates: 21000, epoch: 79, iterations: 21000, max_updates: 24000, val_time: 01m 57s 815ms, best_update: 17000, best_iteration: 17000, best_val/modality_hotpot/textvqa_accuracy: 0.472720
2022-05-06T21:01:04 | INFO | mmf.trainers.callbacks.logistics : progress: 21100/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7518, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.5405, train/total_loss: 0.7518, train/total_loss/avg: 5.5405, max mem: 20597.0, experiment: run, epoch: 79, num_updates: 21100, iterations: 21100, max_updates: 24000, lr: 0., ups: 0.86, time: 01m 56s 908ms, time_since_start: 06h 06m 08s 559ms, eta: 58m 42s 583ms
2022-05-06T21:03:01 | INFO | mmf.trainers.callbacks.logistics : progress: 21200/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7518, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.5178, train/total_loss: 0.7518, train/total_loss/avg: 5.5178, max mem: 20597.0, experiment: run, epoch: 79, num_updates: 21200, iterations: 21200, max_updates: 24000, lr: 0., ups: 0.86, time: 01m 56s 921ms, time_since_start: 06h 08m 05s 481ms, eta: 56m 41s 492ms
2022-05-06T21:04:49 | INFO | mmf.trainers.callbacks.logistics : progress: 21300/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7518, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.4950, train/total_loss: 0.7518, train/total_loss/avg: 5.4950, max mem: 20597.0, experiment: run, epoch: 80, num_updates: 21300, iterations: 21300, max_updates: 24000, lr: 0., ups: 0.93, time: 01m 47s 741ms, time_since_start: 06h 09m 53s 222ms, eta: 50m 22s 461ms
2022-05-06T21:06:19 | INFO | mmf.trainers.callbacks.logistics : progress: 21400/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7518, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.4726, train/total_loss: 0.7518, train/total_loss/avg: 5.4726, max mem: 20597.0, experiment: run, epoch: 80, num_updates: 21400, iterations: 21400, max_updates: 24000, lr: 0., ups: 1.11, time: 01m 30s 248ms, time_since_start: 06h 11m 23s 471ms, eta: 40m 37s 984ms
2022-05-06T21:07:51 | INFO | mmf.trainers.callbacks.logistics : progress: 21500/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7518, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.4505, train/total_loss: 0.7518, train/total_loss/avg: 5.4505, max mem: 20597.0, experiment: run, epoch: 80, num_updates: 21500, iterations: 21500, max_updates: 24000, lr: 0., ups: 1.10, time: 01m 31s 259ms, time_since_start: 06h 12m 54s 730ms, eta: 39m 30s 460ms
2022-05-06T21:09:24 | INFO | mmf.trainers.callbacks.logistics : progress: 21600/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7382, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.4286, train/total_loss: 0.7382, train/total_loss/avg: 5.4286, max mem: 20597.0, experiment: run, epoch: 81, num_updates: 21600, iterations: 21600, max_updates: 24000, lr: 0., ups: 1.08, time: 01m 33s 046ms, time_since_start: 06h 14m 27s 776ms, eta: 38m 40s 200ms
2022-05-06T21:10:55 | INFO | mmf.trainers.callbacks.logistics : progress: 21700/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7456, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.4070, train/total_loss: 0.7456, train/total_loss/avg: 5.4070, max mem: 20597.0, experiment: run, epoch: 81, num_updates: 21700, iterations: 21700, max_updates: 24000, lr: 0., ups: 1.10, time: 01m 31s 027ms, time_since_start: 06h 15m 58s 803ms, eta: 36m 15s 276ms
2022-05-06T21:12:32 | INFO | mmf.trainers.callbacks.logistics : progress: 21800/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7456, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.3854, train/total_loss: 0.7456, train/total_loss/avg: 5.3854, max mem: 20597.0, experiment: run, epoch: 82, num_updates: 21800, iterations: 21800, max_updates: 24000, lr: 0., ups: 1.03, time: 01m 37s 312ms, time_since_start: 06h 17m 36s 116ms, eta: 37m 04s 380ms
2022-05-06T21:14:03 | INFO | mmf.trainers.callbacks.logistics : progress: 21900/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7456, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.3641, train/total_loss: 0.7456, train/total_loss/avg: 5.3641, max mem: 20597.0, experiment: run, epoch: 82, num_updates: 21900, iterations: 21900, max_updates: 24000, lr: 0., ups: 1.11, time: 01m 30s 971ms, time_since_start: 06h 19m 07s 088ms, eta: 33m 04s 905ms
2022-05-06T21:15:36 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-06T21:15:36 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T21:15:37 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T21:15:41 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T21:15:41 | INFO | mmf.trainers.callbacks.logistics : progress: 22000/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7280, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.3429, train/total_loss: 0.7280, train/total_loss/avg: 5.3429, max mem: 20597.0, experiment: run, epoch: 82, num_updates: 22000, iterations: 22000, max_updates: 24000, lr: 0., ups: 1.02, time: 01m 38s 355ms, time_since_start: 06h 20m 45s 444ms, eta: 34m 03s 831ms
2022-05-06T21:15:41 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-06T21:15:41 | INFO | mmf.common.test_reporter : Predicting for modality_hotpot
2022-05-06T21:16:33 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 39
2022-05-06T21:16:33 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-06T21:16:35 | INFO | mmf.trainers.callbacks.logistics : progress: 22000/24000, val/modality_hotpot/m4c_decoding_bce_with_mask: 7.4171, val/total_loss: 7.4171, val/modality_hotpot/textvqa_accuracy: 0.4693, num_updates: 22000, epoch: 82, iterations: 22000, max_updates: 24000, val_time: 53s 631ms, best_update: 17000, best_iteration: 17000, best_val/modality_hotpot/textvqa_accuracy: 0.472720
2022-05-06T21:18:05 | INFO | mmf.trainers.callbacks.logistics : progress: 22100/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7280, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.3220, train/total_loss: 0.7280, train/total_loss/avg: 5.3220, max mem: 20597.0, experiment: run, epoch: 83, num_updates: 22100, iterations: 22100, max_updates: 24000, lr: 0., ups: 1.12, time: 01m 29s 997ms, time_since_start: 06h 23m 09s 073ms, eta: 29m 36s 633ms
2022-05-06T21:19:35 | INFO | mmf.trainers.callbacks.logistics : progress: 22200/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7269, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.3013, train/total_loss: 0.7269, train/total_loss/avg: 5.3013, max mem: 20597.0, experiment: run, epoch: 83, num_updates: 22200, iterations: 22200, max_updates: 24000, lr: 0., ups: 1.12, time: 01m 29s 786ms, time_since_start: 06h 24m 38s 860ms, eta: 27m 59s 195ms
2022-05-06T21:21:09 | INFO | mmf.trainers.callbacks.logistics : progress: 22300/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7269, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.2806, train/total_loss: 0.7269, train/total_loss/avg: 5.2806, max mem: 20597.0, experiment: run, epoch: 83, num_updates: 22300, iterations: 22300, max_updates: 24000, lr: 0., ups: 1.08, time: 01m 33s 900ms, time_since_start: 06h 26m 12s 760ms, eta: 27m 38s 562ms
2022-05-06T21:22:42 | INFO | mmf.trainers.callbacks.logistics : progress: 22400/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7269, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.2607, train/total_loss: 0.7269, train/total_loss/avg: 5.2607, max mem: 20597.0, experiment: run, epoch: 84, num_updates: 22400, iterations: 22400, max_updates: 24000, lr: 0., ups: 1.08, time: 01m 33s 806ms, time_since_start: 06h 27m 46s 566ms, eta: 25m 59s 432ms
2022-05-06T21:24:14 | INFO | mmf.trainers.callbacks.logistics : progress: 22500/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7255, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.2401, train/total_loss: 0.7255, train/total_loss/avg: 5.2401, max mem: 20597.0, experiment: run, epoch: 84, num_updates: 22500, iterations: 22500, max_updates: 24000, lr: 0., ups: 1.10, time: 01m 31s 960ms, time_since_start: 06h 29m 18s 527ms, eta: 23m 53s 208ms
2022-05-06T21:25:44 | INFO | mmf.trainers.callbacks.logistics : progress: 22600/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7255, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.2205, train/total_loss: 0.7255, train/total_loss/avg: 5.2205, max mem: 20597.0, experiment: run, epoch: 85, num_updates: 22600, iterations: 22600, max_updates: 24000, lr: 0., ups: 1.12, time: 01m 29s 479ms, time_since_start: 06h 30m 48s 007ms, eta: 21m 41s 574ms
2022-05-06T21:27:13 | INFO | mmf.trainers.callbacks.logistics : progress: 22700/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7245, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.2004, train/total_loss: 0.7245, train/total_loss/avg: 5.2004, max mem: 20597.0, experiment: run, epoch: 85, num_updates: 22700, iterations: 22700, max_updates: 24000, lr: 0., ups: 1.12, time: 01m 29s 200ms, time_since_start: 06h 32m 17s 208ms, eta: 20m 04s 837ms
2022-05-06T21:28:44 | INFO | mmf.trainers.callbacks.logistics : progress: 22800/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7240, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.1806, train/total_loss: 0.7240, train/total_loss/avg: 5.1806, max mem: 20597.0, experiment: run, epoch: 85, num_updates: 22800, iterations: 22800, max_updates: 24000, lr: 0., ups: 1.10, time: 01m 31s 466ms, time_since_start: 06h 33m 48s 675ms, eta: 19m 402ms
2022-05-06T21:30:19 | INFO | mmf.trainers.callbacks.logistics : progress: 22900/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7228, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.1609, train/total_loss: 0.7228, train/total_loss/avg: 5.1609, max mem: 20597.0, experiment: run, epoch: 86, num_updates: 22900, iterations: 22900, max_updates: 24000, lr: 0., ups: 1.06, time: 01m 34s 514ms, time_since_start: 06h 35m 23s 189ms, eta: 18m 203ms
2022-05-06T21:31:47 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-06T21:31:47 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T21:31:49 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T21:31:55 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T21:31:55 | INFO | mmf.trainers.callbacks.logistics : progress: 23000/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7228, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.1418, train/total_loss: 0.7228, train/total_loss/avg: 5.1418, max mem: 20597.0, experiment: run, epoch: 86, num_updates: 23000, iterations: 23000, max_updates: 24000, lr: 0., ups: 1.04, time: 01m 36s 000ms, time_since_start: 06h 36m 59s 189ms, eta: 16m 37s 444ms
2022-05-06T21:31:55 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-06T21:31:55 | INFO | mmf.common.test_reporter : Predicting for modality_hotpot
2022-05-06T21:32:47 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 39
2022-05-06T21:32:47 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-06T21:32:49 | INFO | mmf.trainers.callbacks.logistics : progress: 23000/24000, val/modality_hotpot/m4c_decoding_bce_with_mask: 7.3884, val/total_loss: 7.3884, val/modality_hotpot/textvqa_accuracy: 0.4698, num_updates: 23000, epoch: 86, iterations: 23000, max_updates: 24000, val_time: 53s 729ms, best_update: 17000, best_iteration: 17000, best_val/modality_hotpot/textvqa_accuracy: 0.472720
2022-05-06T21:34:18 | INFO | mmf.trainers.callbacks.logistics : progress: 23100/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7228, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.1231, train/total_loss: 0.7228, train/total_loss/avg: 5.1231, max mem: 20597.0, experiment: run, epoch: 86, num_updates: 23100, iterations: 23100, max_updates: 24000, lr: 0., ups: 1.14, time: 01m 28s 936ms, time_since_start: 06h 39m 21s 856ms, eta: 13m 51s 643ms
2022-05-06T21:35:53 | INFO | mmf.trainers.callbacks.logistics : progress: 23200/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7228, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.1042, train/total_loss: 0.7228, train/total_loss/avg: 5.1042, max mem: 20597.0, experiment: run, epoch: 87, num_updates: 23200, iterations: 23200, max_updates: 24000, lr: 0., ups: 1.05, time: 01m 35s 690ms, time_since_start: 06h 40m 57s 547ms, eta: 13m 15s 383ms
2022-05-06T21:37:21 | INFO | mmf.trainers.callbacks.logistics : progress: 23300/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7240, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.0856, train/total_loss: 0.7240, train/total_loss/avg: 5.0856, max mem: 20597.0, experiment: run, epoch: 87, num_updates: 23300, iterations: 23300, max_updates: 24000, lr: 0., ups: 1.15, time: 01m 27s 746ms, time_since_start: 06h 42m 25s 293ms, eta: 10m 38s 176ms
2022-05-06T21:39:07 | INFO | mmf.trainers.callbacks.logistics : progress: 23400/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7245, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.0670, train/total_loss: 0.7245, train/total_loss/avg: 5.0670, max mem: 20597.0, experiment: run, epoch: 87, num_updates: 23400, iterations: 23400, max_updates: 24000, lr: 0., ups: 0.95, time: 01m 45s 782ms, time_since_start: 06h 44m 11s 076ms, eta: 10m 59s 447ms
2022-05-06T21:40:59 | INFO | mmf.trainers.callbacks.logistics : progress: 23500/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7240, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.0486, train/total_loss: 0.7240, train/total_loss/avg: 5.0486, max mem: 20597.0, experiment: run, epoch: 88, num_updates: 23500, iterations: 23500, max_updates: 24000, lr: 0., ups: 0.90, time: 01m 51s 894ms, time_since_start: 06h 46m 02s 971ms, eta: 09m 41s 293ms
2022-05-06T21:42:32 | INFO | mmf.trainers.callbacks.logistics : progress: 23600/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7240, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.0302, train/total_loss: 0.7240, train/total_loss/avg: 5.0302, max mem: 20597.0, experiment: run, epoch: 88, num_updates: 23600, iterations: 23600, max_updates: 24000, lr: 0., ups: 1.08, time: 01m 33s 323ms, time_since_start: 06h 47m 36s 294ms, eta: 06m 27s 850ms
2022-05-06T21:44:02 | INFO | mmf.trainers.callbacks.logistics : progress: 23700/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7225, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 5.0118, train/total_loss: 0.7225, train/total_loss/avg: 5.0118, max mem: 20597.0, experiment: run, epoch: 89, num_updates: 23700, iterations: 23700, max_updates: 24000, lr: 0., ups: 1.12, time: 01m 29s 526ms, time_since_start: 06h 49m 05s 821ms, eta: 04m 39s 055ms
2022-05-06T21:45:32 | INFO | mmf.trainers.callbacks.logistics : progress: 23800/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7225, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 4.9935, train/total_loss: 0.7225, train/total_loss/avg: 4.9935, max mem: 20597.0, experiment: run, epoch: 89, num_updates: 23800, iterations: 23800, max_updates: 24000, lr: 0., ups: 1.11, time: 01m 30s 823ms, time_since_start: 06h 50m 36s 645ms, eta: 03m 08s 732ms
2022-05-06T21:47:03 | INFO | mmf.trainers.callbacks.logistics : progress: 23900/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7225, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 4.9758, train/total_loss: 0.7225, train/total_loss/avg: 4.9758, max mem: 20597.0, experiment: run, epoch: 89, num_updates: 23900, iterations: 23900, max_updates: 24000, lr: 0., ups: 1.10, time: 01m 31s 038ms, time_since_start: 06h 52m 07s 683ms, eta: 01m 34s 589ms
2022-05-06T21:48:36 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-06T21:48:36 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-06T21:48:37 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-06T21:48:42 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-06T21:48:42 | INFO | mmf.trainers.callbacks.logistics : progress: 24000/24000, train/modality_hotpot/m4c_decoding_bce_with_mask: 0.7245, train/modality_hotpot/m4c_decoding_bce_with_mask/avg: 4.9582, train/total_loss: 0.7245, train/total_loss/avg: 4.9582, max mem: 20597.0, experiment: run, epoch: 90, num_updates: 24000, iterations: 24000, max_updates: 24000, lr: 0., ups: 1.02, time: 01m 38s 210ms, time_since_start: 06h 53m 45s 894ms, eta: 0ms
2022-05-06T21:48:42 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-06T21:48:42 | INFO | mmf.common.test_reporter : Predicting for modality_hotpot
2022-05-06T21:49:33 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 39
2022-05-06T21:49:33 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-06T21:49:36 | INFO | mmf.trainers.callbacks.logistics : progress: 24000/24000, val/modality_hotpot/m4c_decoding_bce_with_mask: 7.3633, val/total_loss: 7.3633, val/modality_hotpot/textvqa_accuracy: 0.4690, num_updates: 24000, epoch: 90, iterations: 24000, max_updates: 24000, val_time: 53s 806ms, best_update: 17000, best_iteration: 17000, best_val/modality_hotpot/textvqa_accuracy: 0.472720
2022-05-06T21:49:36 | INFO | mmf.trainers.core.training_loop : Stepping into final validation check
2022-05-06T21:49:36 | INFO | mmf.utils.checkpoint : Restoring checkpoint
2022-05-06T21:49:36 | INFO | mmf.utils.checkpoint : Loading checkpoint
2022-05-06T21:49:37 | INFO | mmf.utils.checkpoint : 

===========================================================
2022-05-06T21:49:37 | INFO | mmf.utils.checkpoint : Checkpoint loaded.
2022-05-06T21:49:37 | INFO | mmf.utils.checkpoint : Current num updates: 17000
2022-05-06T21:49:37 | INFO | mmf.utils.checkpoint : Current iteration: 17000
2022-05-06T21:49:37 | INFO | mmf.utils.checkpoint : Current epoch: 64
2022-05-06T21:49:37 | INFO | mmf.trainers.mmf_trainer : Starting inference on test set
2022-05-06T21:49:37 | INFO | mmf.common.test_reporter : Predicting for modality_hotpot
2022-05-06T21:49:42 | WARNING | py.warnings : /usr1/data/yuweiwu/mmf/mmf/modules/losses.py:113: UserWarning: Sample list has not field 'targets', are you sure that your ImDB has labels? you may have wanted to run with evaluation.predict=true
  "Sample list has not field 'targets', are you "

2022-05-06T21:49:42 | WARNING | py.warnings : /usr1/data/yuweiwu/mmf/mmf/modules/losses.py:113: UserWarning: Sample list has not field 'targets', are you sure that your ImDB has labels? you may have wanted to run with evaluation.predict=true
  "Sample list has not field 'targets', are you "

2022-05-06T21:50:30 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 45
2022-05-06T21:50:30 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-07T13:13:31 | INFO | mmf : Logging to: save/hotpot_modality_finetune/train.log
2022-05-07T13:13:31 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['dataset=modality_hotpot', 'model=hotpot_net', 'config=save/hotpot_modality_finetune/config.yaml', 'env.save_dir=save/hotpot_modality_finetune/', 'run_type=val', 'checkpoint.resume=True', 'checkpoint.resume_best=True', 'evaluation.predict=true'])
2022-05-07T13:13:31 | INFO | mmf_cli.run : Torch version: 1.9.0+cu111
2022-05-07T13:13:31 | INFO | mmf.utils.general : CUDA Device 0 is: NVIDIA RTX A6000
2022-05-07T13:13:31 | INFO | mmf_cli.run : Using seed 51040596
2022-05-07T13:13:31 | INFO | mmf_cli.run : Building trainer
2022-05-07T13:13:31 | INFO | mmf_cli.run : Loading trainer
2022-05-07T13:13:31 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2022-05-07T13:13:34 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-07T13:13:34 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-07T13:13:34 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-07T13:13:34 | INFO | mmf.trainers.mmf_trainer : Loading model
2022-05-07T13:13:34 | INFO | mmf.trainers.mmf_trainer : hotpot_net, {'hotpot_net': {'pretrain': False, 'do_mask_finetuning': False, 'use_lorra': False, 'use_mmt': True, 'use_question': True, 'use_ocr': True, 'use_object': True, 'use_whole_img': False, 'whole_img_model': 'vit', 'whole_img_model_layer': 5, 'lr_scale_frcn': 0.1, 'lr_scale_text_bert': 0.1, 'lr_scale_mmt': 1.0, 'text_bert_init_from_bert_base': True, 'text_bert': {'num_hidden_layers': 3}, 'obj': {'mmt_in_dim': 2816, 'dropout_prob': 0.1}, 'ocr': {'mmt_in_dim': 3420, 'dropout_prob': 0.1}, 'whole_img': {'mmt_in_dim': 768}, 'mmt': {'hidden_size': 768, 'num_hidden_layers': 4}, 'classifier': {'type': 'linear', 'ocr_max_num': 100, 'ocr_ptr_net': {'hidden_size': 768, 'query_key_size': 768}, 'params': {}}, 'model_data_dir': './cache/data', 'losses': [{'type': 'm4c_decoding_bce_with_mask'}], 'model': 'hotpot_net'}}
2022-05-07T13:13:34 | INFO | mmf.trainers.mmf_trainer : Building model
2022-05-07T13:14:33 | INFO | mmf : Logging to: save/hotpot_modality_finetune/train.log
2022-05-07T13:14:33 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['dataset=modality_hotpot', 'model=hotpot_net', 'config=save/hotpot_modality_finetune/config.yaml', 'env.save_dir=save/hotpot_modality_finetune/', 'run_type=val', 'checkpoint.resume=True', 'checkpoint.resume_best=True', 'evaluation.predict=true'])
2022-05-07T13:14:33 | INFO | mmf_cli.run : Torch version: 1.9.0+cu111
2022-05-07T13:14:33 | INFO | mmf.utils.general : CUDA Device 0 is: NVIDIA RTX A6000
2022-05-07T13:14:33 | INFO | mmf_cli.run : Using seed 51040596
2022-05-07T13:14:33 | INFO | mmf_cli.run : Building trainer
2022-05-07T13:14:33 | INFO | mmf_cli.run : Loading trainer
2022-05-07T13:14:33 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2022-05-07T13:14:36 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-07T13:14:36 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-07T13:14:36 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-07T13:14:36 | INFO | mmf.trainers.mmf_trainer : Loading model
2022-05-07T13:14:36 | INFO | mmf.trainers.mmf_trainer : hotpot_net, {'hotpot_net': {'pretrain': False, 'do_mask_finetuning': False, 'use_lorra': False, 'use_mmt': True, 'use_question': True, 'use_ocr': True, 'use_object': True, 'use_whole_img': False, 'whole_img_model': 'vit', 'whole_img_model_layer': 5, 'lr_scale_frcn': 0.1, 'lr_scale_text_bert': 0.1, 'lr_scale_mmt': 1.0, 'text_bert_init_from_bert_base': True, 'text_bert': {'num_hidden_layers': 3}, 'obj': {'mmt_in_dim': 2816, 'dropout_prob': 0.1}, 'ocr': {'mmt_in_dim': 3420, 'dropout_prob': 0.1}, 'whole_img': {'mmt_in_dim': 768}, 'mmt': {'hidden_size': 768, 'num_hidden_layers': 4}, 'classifier': {'type': 'linear', 'ocr_max_num': 100, 'ocr_ptr_net': {'hidden_size': 768, 'query_key_size': 768}, 'params': {}}, 'model_data_dir': './cache/data', 'losses': [{'type': 'm4c_decoding_bce_with_mask'}], 'model': 'hotpot_net'}}
2022-05-07T13:14:36 | INFO | mmf.trainers.mmf_trainer : Building model
2022-05-07T13:14:40 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2022-05-07T13:14:40 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2022-05-07T13:14:40 | WARNING | py.warnings : /usr1/data/yuweiwu/mmf/mmf/utils/build.py:474: UserWarning: No type for scheduler specified even though lr_scheduler is True, setting default to 'Pythia'
  "No type for scheduler specified even though lr_scheduler is True, "

2022-05-07T13:14:40 | WARNING | py.warnings : /usr1/data/yuweiwu/mmf/mmf/utils/build.py:474: UserWarning: No type for scheduler specified even though lr_scheduler is True, setting default to 'Pythia'
  "No type for scheduler specified even though lr_scheduler is True, "

2022-05-07T13:14:40 | WARNING | py.warnings : /usr1/data/yuweiwu/mmf/mmf/utils/build.py:480: UserWarning: scheduler attributes has no params defined, defaulting to {}.
  warnings.warn("scheduler attributes has no params defined, defaulting to {}.")

2022-05-07T13:14:40 | WARNING | py.warnings : /usr1/data/yuweiwu/mmf/mmf/utils/build.py:480: UserWarning: scheduler attributes has no params defined, defaulting to {}.
  warnings.warn("scheduler attributes has no params defined, defaulting to {}.")

2022-05-07T13:14:40 | INFO | mmf.utils.checkpoint : Loading checkpoint
2022-05-07T13:14:40 | WARNING | mmf : Key data_parallel is not present in registry, returning default value of None
2022-05-07T13:14:40 | WARNING | mmf : Key distributed is not present in registry, returning default value of None
2022-05-07T13:14:40 | INFO | mmf.utils.checkpoint : 

===========================================================
2022-05-07T13:14:40 | INFO | mmf.utils.checkpoint : Checkpoint loaded.
2022-05-07T13:14:40 | INFO | mmf.utils.checkpoint : Current num updates: 17000
2022-05-07T13:14:40 | INFO | mmf.utils.checkpoint : Current iteration: 17000
2022-05-07T13:14:40 | INFO | mmf.utils.checkpoint : Current epoch: 64
2022-05-07T13:14:40 | INFO | mmf_cli.run : === Start Inference ===
2022-05-07T13:14:40 | INFO | mmf.trainers.core.evaluation_loop : Starting val inference predictions
2022-05-07T13:14:40 | INFO | mmf.common.test_reporter : Predicting for modality_hotpot
2022-05-07T13:17:35 | INFO | mmf : Logging to: save/hotpot_modality_finetune/train.log
2022-05-07T13:17:35 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['dataset=modality_hotpot', 'model=hotpot_net', 'config=save/hotpot_modality_finetune/config.yaml', 'run_type=val', 'checkpoint.resume_file=save/hotpot_modality_finetune/best.ckpt', 'evaluation.predict=true'])
2022-05-07T13:17:35 | INFO | mmf_cli.run : Torch version: 1.9.0+cu111
2022-05-07T13:17:35 | INFO | mmf.utils.general : CUDA Device 0 is: NVIDIA RTX A6000
2022-05-07T13:17:35 | INFO | mmf_cli.run : Using seed 51040596
2022-05-07T13:17:35 | INFO | mmf_cli.run : Building trainer
2022-05-07T13:17:35 | INFO | mmf_cli.run : Loading trainer
2022-05-07T13:17:35 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2022-05-07T13:17:38 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-07T13:17:38 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-07T13:17:38 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-07T13:17:38 | INFO | mmf.trainers.mmf_trainer : Loading model
2022-05-07T13:17:38 | INFO | mmf.trainers.mmf_trainer : hotpot_net, {'hotpot_net': {'pretrain': False, 'do_mask_finetuning': False, 'use_lorra': False, 'use_mmt': True, 'use_question': True, 'use_ocr': True, 'use_object': True, 'use_whole_img': False, 'whole_img_model': 'vit', 'whole_img_model_layer': 5, 'lr_scale_frcn': 0.1, 'lr_scale_text_bert': 0.1, 'lr_scale_mmt': 1.0, 'text_bert_init_from_bert_base': True, 'text_bert': {'num_hidden_layers': 3}, 'obj': {'mmt_in_dim': 2816, 'dropout_prob': 0.1}, 'ocr': {'mmt_in_dim': 3420, 'dropout_prob': 0.1}, 'whole_img': {'mmt_in_dim': 768}, 'mmt': {'hidden_size': 768, 'num_hidden_layers': 4}, 'classifier': {'type': 'linear', 'ocr_max_num': 100, 'ocr_ptr_net': {'hidden_size': 768, 'query_key_size': 768}, 'params': {}}, 'model_data_dir': './cache/data', 'losses': [{'type': 'm4c_decoding_bce_with_mask'}], 'model': 'hotpot_net'}}
2022-05-07T13:17:38 | INFO | mmf.trainers.mmf_trainer : Building model
2022-05-07T13:17:42 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2022-05-07T13:17:42 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2022-05-07T13:17:42 | WARNING | py.warnings : /usr1/data/yuweiwu/mmf/mmf/utils/build.py:474: UserWarning: No type for scheduler specified even though lr_scheduler is True, setting default to 'Pythia'
  "No type for scheduler specified even though lr_scheduler is True, "

2022-05-07T13:17:42 | WARNING | py.warnings : /usr1/data/yuweiwu/mmf/mmf/utils/build.py:474: UserWarning: No type for scheduler specified even though lr_scheduler is True, setting default to 'Pythia'
  "No type for scheduler specified even though lr_scheduler is True, "

2022-05-07T13:17:42 | WARNING | py.warnings : /usr1/data/yuweiwu/mmf/mmf/utils/build.py:480: UserWarning: scheduler attributes has no params defined, defaulting to {}.
  warnings.warn("scheduler attributes has no params defined, defaulting to {}.")

2022-05-07T13:17:42 | WARNING | py.warnings : /usr1/data/yuweiwu/mmf/mmf/utils/build.py:480: UserWarning: scheduler attributes has no params defined, defaulting to {}.
  warnings.warn("scheduler attributes has no params defined, defaulting to {}.")

2022-05-07T13:17:42 | INFO | mmf.utils.checkpoint : Loading checkpoint
2022-05-07T13:17:42 | WARNING | mmf : Key data_parallel is not present in registry, returning default value of None
2022-05-07T13:17:42 | WARNING | mmf : Key distributed is not present in registry, returning default value of None
2022-05-07T13:17:42 | INFO | mmf.utils.checkpoint : 

===========================================================
2022-05-07T13:17:42 | INFO | mmf.utils.checkpoint : Checkpoint loaded.
2022-05-07T13:17:42 | INFO | mmf.utils.checkpoint : Current num updates: 17000
2022-05-07T13:17:42 | INFO | mmf.utils.checkpoint : Current iteration: 17000
2022-05-07T13:17:42 | INFO | mmf.utils.checkpoint : Current epoch: 64
2022-05-07T13:17:42 | INFO | mmf_cli.run : === Start Inference ===
2022-05-07T13:17:42 | INFO | mmf.trainers.core.evaluation_loop : Starting val inference predictions
2022-05-07T13:17:42 | INFO | mmf.common.test_reporter : Predicting for modality_hotpot
2022-05-07T13:19:42 | INFO | mmf : Logging to: save/hotpot_modality_finetune/train.log
2022-05-07T13:19:42 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['dataset=modality_hotpot', 'model=hotpot_net', 'config=save/hotpot_modality_finetune/config.yaml', 'run_type=val', 'checkpoint.resume_file=save/hotpot_modality_finetune/best.ckpt'])
2022-05-07T13:19:42 | INFO | mmf_cli.run : Torch version: 1.9.0+cu111
2022-05-07T13:19:42 | INFO | mmf.utils.general : CUDA Device 0 is: NVIDIA RTX A6000
2022-05-07T13:19:42 | INFO | mmf_cli.run : Using seed 51040596
2022-05-07T13:19:42 | INFO | mmf_cli.run : Building trainer
2022-05-07T13:19:42 | INFO | mmf_cli.run : Loading trainer
2022-05-07T13:19:42 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2022-05-07T13:19:44 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-07T13:19:44 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-07T13:19:44 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-07T13:19:44 | INFO | mmf.trainers.mmf_trainer : Loading model
2022-05-07T13:19:44 | INFO | mmf.trainers.mmf_trainer : hotpot_net, {'hotpot_net': {'pretrain': False, 'do_mask_finetuning': False, 'use_lorra': False, 'use_mmt': True, 'use_question': True, 'use_ocr': True, 'use_object': True, 'use_whole_img': False, 'whole_img_model': 'vit', 'whole_img_model_layer': 5, 'lr_scale_frcn': 0.1, 'lr_scale_text_bert': 0.1, 'lr_scale_mmt': 1.0, 'text_bert_init_from_bert_base': True, 'text_bert': {'num_hidden_layers': 3}, 'obj': {'mmt_in_dim': 2816, 'dropout_prob': 0.1}, 'ocr': {'mmt_in_dim': 3420, 'dropout_prob': 0.1}, 'whole_img': {'mmt_in_dim': 768}, 'mmt': {'hidden_size': 768, 'num_hidden_layers': 4}, 'classifier': {'type': 'linear', 'ocr_max_num': 100, 'ocr_ptr_net': {'hidden_size': 768, 'query_key_size': 768}, 'params': {}}, 'model_data_dir': './cache/data', 'losses': [{'type': 'm4c_decoding_bce_with_mask'}], 'model': 'hotpot_net'}}
2022-05-07T13:19:44 | INFO | mmf.trainers.mmf_trainer : Building model
2022-05-07T13:19:49 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2022-05-07T13:19:49 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2022-05-07T13:19:49 | WARNING | py.warnings : /usr1/data/yuweiwu/mmf/mmf/utils/build.py:474: UserWarning: No type for scheduler specified even though lr_scheduler is True, setting default to 'Pythia'
  "No type for scheduler specified even though lr_scheduler is True, "

2022-05-07T13:19:49 | WARNING | py.warnings : /usr1/data/yuweiwu/mmf/mmf/utils/build.py:474: UserWarning: No type for scheduler specified even though lr_scheduler is True, setting default to 'Pythia'
  "No type for scheduler specified even though lr_scheduler is True, "

2022-05-07T13:19:49 | WARNING | py.warnings : /usr1/data/yuweiwu/mmf/mmf/utils/build.py:480: UserWarning: scheduler attributes has no params defined, defaulting to {}.
  warnings.warn("scheduler attributes has no params defined, defaulting to {}.")

2022-05-07T13:19:49 | WARNING | py.warnings : /usr1/data/yuweiwu/mmf/mmf/utils/build.py:480: UserWarning: scheduler attributes has no params defined, defaulting to {}.
  warnings.warn("scheduler attributes has no params defined, defaulting to {}.")

2022-05-07T13:19:49 | INFO | mmf.utils.checkpoint : Loading checkpoint
2022-05-07T13:20:04 | INFO | mmf : Logging to: save/hotpot_modality_finetune/train.log
2022-05-07T13:20:04 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['dataset=modality_hotpot', 'model=hotpot_net', 'config=save/hotpot_modality_finetune/config.yaml', 'run_type=val', 'checkpoint.resume_file=save/hotpot_modality_finetune/best.ckpt'])
2022-05-07T13:20:04 | INFO | mmf_cli.run : Torch version: 1.9.0+cu111
2022-05-07T13:20:04 | INFO | mmf.utils.general : CUDA Device 0 is: NVIDIA RTX A6000
2022-05-07T13:20:04 | INFO | mmf_cli.run : Using seed 51040596
2022-05-07T13:20:04 | INFO | mmf_cli.run : Building trainer
2022-05-07T13:20:04 | INFO | mmf_cli.run : Loading trainer
2022-05-07T13:20:04 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2022-05-07T13:20:07 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-07T13:20:07 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-07T13:20:07 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-07T13:20:07 | INFO | mmf.trainers.mmf_trainer : Loading model
2022-05-07T13:20:07 | INFO | mmf.trainers.mmf_trainer : hotpot_net, {'hotpot_net': {'pretrain': False, 'do_mask_finetuning': False, 'use_lorra': False, 'use_mmt': True, 'use_question': True, 'use_ocr': True, 'use_object': True, 'use_whole_img': False, 'whole_img_model': 'vit', 'whole_img_model_layer': 5, 'lr_scale_frcn': 0.1, 'lr_scale_text_bert': 0.1, 'lr_scale_mmt': 1.0, 'text_bert_init_from_bert_base': True, 'text_bert': {'num_hidden_layers': 3}, 'obj': {'mmt_in_dim': 2816, 'dropout_prob': 0.1}, 'ocr': {'mmt_in_dim': 3420, 'dropout_prob': 0.1}, 'whole_img': {'mmt_in_dim': 768}, 'mmt': {'hidden_size': 768, 'num_hidden_layers': 4}, 'classifier': {'type': 'linear', 'ocr_max_num': 100, 'ocr_ptr_net': {'hidden_size': 768, 'query_key_size': 768}, 'params': {}}, 'model_data_dir': './cache/data', 'losses': [{'type': 'm4c_decoding_bce_with_mask'}], 'model': 'hotpot_net'}}
2022-05-07T13:20:07 | INFO | mmf.trainers.mmf_trainer : Building model
2022-05-07T13:20:11 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2022-05-07T13:20:11 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2022-05-07T13:20:11 | WARNING | py.warnings : /usr1/data/yuweiwu/mmf/mmf/utils/build.py:474: UserWarning: No type for scheduler specified even though lr_scheduler is True, setting default to 'Pythia'
  "No type for scheduler specified even though lr_scheduler is True, "

2022-05-07T13:20:11 | WARNING | py.warnings : /usr1/data/yuweiwu/mmf/mmf/utils/build.py:474: UserWarning: No type for scheduler specified even though lr_scheduler is True, setting default to 'Pythia'
  "No type for scheduler specified even though lr_scheduler is True, "

2022-05-07T13:20:11 | WARNING | py.warnings : /usr1/data/yuweiwu/mmf/mmf/utils/build.py:480: UserWarning: scheduler attributes has no params defined, defaulting to {}.
  warnings.warn("scheduler attributes has no params defined, defaulting to {}.")

2022-05-07T13:20:11 | WARNING | py.warnings : /usr1/data/yuweiwu/mmf/mmf/utils/build.py:480: UserWarning: scheduler attributes has no params defined, defaulting to {}.
  warnings.warn("scheduler attributes has no params defined, defaulting to {}.")

2022-05-07T13:20:11 | INFO | mmf.utils.checkpoint : Loading checkpoint
2022-05-07T13:20:11 | WARNING | mmf : Key data_parallel is not present in registry, returning default value of None
2022-05-07T13:20:11 | WARNING | mmf : Key distributed is not present in registry, returning default value of None
2022-05-07T13:20:11 | INFO | mmf.utils.checkpoint : 

===========================================================
2022-05-07T13:20:11 | INFO | mmf.utils.checkpoint : Checkpoint loaded.
2022-05-07T13:20:11 | INFO | mmf.utils.checkpoint : Current num updates: 17000
2022-05-07T13:20:11 | INFO | mmf.utils.checkpoint : Current iteration: 17000
2022-05-07T13:20:11 | INFO | mmf.utils.checkpoint : Current epoch: 64
2022-05-07T13:20:11 | INFO | mmf_cli.run : === Start Training ===
2022-05-07T13:20:11 | INFO | mmf.trainers.core.evaluation_loop : Starting val inference predictions
2022-05-07T13:20:11 | INFO | mmf.common.test_reporter : Predicting for modality_hotpot
2022-05-07T13:21:48 | INFO | mmf : Logging to: save/hotpot_modality_finetune/train.log
2022-05-07T13:21:48 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['dataset=modality_hotpot', 'model=hotpot_net', 'config=save/hotpot_modality_finetune/config.yaml', 'run_type=val', 'checkpoint.resume_file=save/hotpot_modality_finetune/best.ckpt', 'evaluation.predict=true'])
2022-05-07T13:21:48 | INFO | mmf_cli.run : Torch version: 1.9.0+cu111
2022-05-07T13:21:48 | INFO | mmf.utils.general : CUDA Device 0 is: NVIDIA RTX A6000
2022-05-07T13:21:48 | INFO | mmf_cli.run : Using seed 51040596
2022-05-07T13:21:48 | INFO | mmf_cli.run : Building trainer
2022-05-07T13:21:48 | INFO | mmf_cli.run : Loading trainer
2022-05-07T13:21:48 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2022-05-07T13:21:52 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-07T13:21:52 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-07T13:21:52 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-07T13:21:52 | INFO | mmf.trainers.mmf_trainer : Loading model
2022-05-07T13:21:52 | INFO | mmf.trainers.mmf_trainer : hotpot_net, {'hotpot_net': {'pretrain': False, 'do_mask_finetuning': False, 'use_lorra': False, 'use_mmt': True, 'use_question': True, 'use_ocr': True, 'use_object': True, 'use_whole_img': False, 'whole_img_model': 'vit', 'whole_img_model_layer': 5, 'lr_scale_frcn': 0.1, 'lr_scale_text_bert': 0.1, 'lr_scale_mmt': 1.0, 'text_bert_init_from_bert_base': True, 'text_bert': {'num_hidden_layers': 3}, 'obj': {'mmt_in_dim': 2816, 'dropout_prob': 0.1}, 'ocr': {'mmt_in_dim': 3420, 'dropout_prob': 0.1}, 'whole_img': {'mmt_in_dim': 768}, 'mmt': {'hidden_size': 768, 'num_hidden_layers': 4}, 'classifier': {'type': 'linear', 'ocr_max_num': 100, 'ocr_ptr_net': {'hidden_size': 768, 'query_key_size': 768}, 'params': {}}, 'model_data_dir': './cache/data', 'losses': [{'type': 'm4c_decoding_bce_with_mask'}], 'model': 'hotpot_net'}}
2022-05-07T13:21:52 | INFO | mmf.trainers.mmf_trainer : Building model
2022-05-07T13:21:55 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2022-05-07T13:21:55 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2022-05-07T13:21:55 | WARNING | py.warnings : /usr1/data/yuweiwu/mmf/mmf/utils/build.py:474: UserWarning: No type for scheduler specified even though lr_scheduler is True, setting default to 'Pythia'
  "No type for scheduler specified even though lr_scheduler is True, "

2022-05-07T13:21:55 | WARNING | py.warnings : /usr1/data/yuweiwu/mmf/mmf/utils/build.py:474: UserWarning: No type for scheduler specified even though lr_scheduler is True, setting default to 'Pythia'
  "No type for scheduler specified even though lr_scheduler is True, "

2022-05-07T13:21:55 | WARNING | py.warnings : /usr1/data/yuweiwu/mmf/mmf/utils/build.py:480: UserWarning: scheduler attributes has no params defined, defaulting to {}.
  warnings.warn("scheduler attributes has no params defined, defaulting to {}.")

2022-05-07T13:21:55 | WARNING | py.warnings : /usr1/data/yuweiwu/mmf/mmf/utils/build.py:480: UserWarning: scheduler attributes has no params defined, defaulting to {}.
  warnings.warn("scheduler attributes has no params defined, defaulting to {}.")

2022-05-07T13:21:55 | INFO | mmf.utils.checkpoint : Loading checkpoint
2022-05-07T13:21:56 | WARNING | mmf : Key data_parallel is not present in registry, returning default value of None
2022-05-07T13:21:56 | WARNING | mmf : Key distributed is not present in registry, returning default value of None
2022-05-07T13:21:56 | INFO | mmf.utils.checkpoint : 

===========================================================
2022-05-07T13:21:56 | INFO | mmf.utils.checkpoint : Checkpoint loaded.
2022-05-07T13:21:56 | INFO | mmf.utils.checkpoint : Current num updates: 17000
2022-05-07T13:21:56 | INFO | mmf.utils.checkpoint : Current iteration: 17000
2022-05-07T13:21:56 | INFO | mmf.utils.checkpoint : Current epoch: 64
2022-05-07T13:21:56 | INFO | mmf_cli.run : === Start Inference ===
2022-05-07T13:21:56 | INFO | mmf.trainers.core.evaluation_loop : Starting val inference predictions
2022-05-07T13:21:56 | INFO | mmf.common.test_reporter : Predicting for modality_hotpot
2022-05-07T13:22:49 | INFO | mmf.common.test_reporter : Wrote predictions for modality_hotpot to /usr1/data/yuweiwu/mmf/save/hotpot_modality_finetune/modality_hotpot_hotpot_net_51040596/reports/modality_hotpot_run_val_2022-05-07T13:22:49.json
2022-05-07T13:22:49 | INFO | mmf.trainers.core.evaluation_loop : Finished predicting. Loaded 39
2022-05-07T13:22:49 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
