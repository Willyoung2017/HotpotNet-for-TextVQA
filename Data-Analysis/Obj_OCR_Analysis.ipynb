{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'what is the brand of this camera?', 'image_id': '003a8ae2ef43b901', 'image_classes': ['Cassette deck', 'Printer', 'Medical equipment', 'Computer mouse', 'Scale', 'Telephone', 'Camera', 'Ipod', 'Remote control'], 'flickr_original_url': 'https://farm2.staticflickr.com/4/5566811_bc00d504a6_o.jpg', 'flickr_300k_url': 'https://farm2.staticflickr.com/4/5566811_bc00d504a6_o.jpg', 'image_width': 1024, 'image_height': 664, 'answers': ['nous les gosses', 'dakota', 'clos culombu', 'dakota digital', 'dakota', 'dakota', 'dakota digital', 'dakota digital', 'dakota', 'dakota'], 'question_tokens': ['what', 'is', 'the', 'brand', 'of', 'this', 'camera'], 'question_id': 34602, 'set_name': 'val'}\n"
     ]
    }
   ],
   "source": [
    "val_text_file = open(\"../Data/TextVQA_0.5.1_val.json\")\n",
    "val_text_data = json.load(val_text_file)\n",
    "print (val_text_data[\"data\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract image id in train | val | test\n",
    "train_image_id_set = set([train_text_data[\"data\"][i][\"image_id\"] for i in range(len(train_text_data[\"data\"]))]) # 21953 image_id\n",
    "val_image_id_set = set([val_text_data[\"data\"][i][\"image_id\"] for i in range(len(val_text_data[\"data\"]))]) # 3166 image_id\n",
    "test_image_id_set = set([test_text_data[\"data\"][i][\"image_id\"] for i in range(len(test_text_data[\"data\"]))]) # 3289 image_id \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCR Token Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.447182617409922\n",
      "12.893240682248894\n",
      "9.597750076010946\n",
      "3166\n"
     ]
    }
   ],
   "source": [
    "# build dictionary about ocr info\n",
    "# key: image id\n",
    "# value: number of ocr tokens detected\n",
    "train_ocr_info_dict = {train_ocr_data[\"data\"][i][\"image_id\"]:len(train_ocr_data[\"data\"][i][\"ocr_info\"]) for i in range(len(train_ocr_data[\"data\"]))}  # 21953 unique images\n",
    "val_ocr_info_dict = {val_ocr_data[\"data\"][i][\"image_id\"]:len(val_ocr_data[\"data\"][i][\"ocr_info\"]) for i in range(len(val_ocr_data[\"data\"]))}  # 3166 unique images\n",
    "test_ocr_info_dict = {test_ocr_data[\"data\"][i][\"image_id\"]:len(test_ocr_data[\"data\"][i][\"ocr_info\"]) for i in range(len(test_ocr_data[\"data\"]))}  # 3289 unique images\n",
    "\n",
    "# compute average ocr token detected in each dataset\n",
    "print (sum(train_ocr_info_dict.values())/len(train_ocr_data[\"data\"])) # there are on average 12.45 ocr tokens detected per training image \n",
    "print (sum(val_ocr_info_dict.values())/len(val_ocr_data[\"data\"])) # there are on average 12.89 ocr tokens detected per validation image\n",
    "print (sum(test_ocr_info_dict.values())/len(test_ocr_data[\"data\"])) # there are on average 9.60 ocr tokens detected per test image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Detection Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.044321960552089\n",
      "5.3092229943145925\n",
      "9.139799792889196\n"
     ]
    }
   ],
   "source": [
    "# construct dataframes of object detection \n",
    "# columns: image id, count of objects detected\n",
    "train_img_obj_count = train_img_df.groupby([\"ImageID\"]).size().reset_index(name='count')\n",
    "val_img_obj_count = val_img_df.groupby([\"ImageID\"]).size().reset_index(name='count')\n",
    "test_img_obj_count = test_img_df.groupby([\"ImageID\"]).size().reset_index(name='count')\n",
    "total_img_obj_count = pd.concat([train_img_obj_count, val_img_obj_count, test_img_obj_count])\n",
    "\n",
    "train_img_obj_count = total_img_obj_count[total_img_obj_count[\"ImageID\"].isin(train_image_id_set)] # 21953 images with 5.04 object detected on average\n",
    "val_img_obj_count = total_img_obj_count[total_img_obj_count[\"ImageID\"].isin(val_image_id_set)] # 3166 images with 5.31 objects detected on average\n",
    "test_img_obj_count = total_img_obj_count[total_img_obj_count[\"ImageID\"].isin(test_image_id_set)] # 2897 images with 9.14 objects detected on average\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
