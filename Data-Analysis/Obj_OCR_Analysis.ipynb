{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text questions\n",
    "train_text_file = open(\"../Data/train/TextVQA_0.5.1_train.json\")\n",
    "val_text_file = open(\"../Data/val/TextVQA_0.5.1_val.json\")\n",
    "test_text_file = open(\"../Data/test/TextVQA_0.5.1_test.json\")\n",
    "\n",
    "# ocr tokens\n",
    "train_ocr_file = open(\"../Data/train/TextVQA_Rosetta_OCR_v0.2_train.json\")\n",
    "val_ocr_file = open(\"../Data/val/TextVQA_Rosetta_OCR_v0.2_val.json\")\n",
    "test_ocr_file = open(\"../Data/test/TextVQA_Rosetta_OCR_v0.2_test.json\")\n",
    "\n",
    "# objects\n",
    "train_img_df = pd.read_csv(\"../Data/train/train-annotations-bbox.csv\")\n",
    "val_img_df = pd.read_csv(\"../Data/val/validation-annotations-bbox.csv\")\n",
    "test_img_df = pd.read_csv(\"../Data/test/test-annotations-bbox.csv\")\n",
    "\n",
    "# extract data from .json \n",
    "#dict_keys(['data', 'dataset_type', 'dataset_name', 'dataset_version'])\n",
    "train_text_data = json.load(train_text_file)\n",
    "val_text_data = json.load(val_text_file)\n",
    "test_text_data = json.load(test_text_file) \n",
    "train_ocr_data = json.load(train_ocr_file) \n",
    "val_ocr_data = json.load(val_ocr_file) \n",
    "test_ocr_data = json.load(test_ocr_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract image id in train | val | test\n",
    "train_image_id_set = set([train_text_data[\"data\"][i][\"image_id\"] for i in range(len(train_text_data[\"data\"]))]) # 21953 image_id\n",
    "val_image_id_set = set([val_text_data[\"data\"][i][\"image_id\"] for i in range(len(val_text_data[\"data\"]))]) # 3166 image_id\n",
    "test_image_id_set = set([test_text_data[\"data\"][i][\"image_id\"] for i in range(len(test_text_data[\"data\"]))]) # 3289 image_id \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCR Token Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.447182617409922\n",
      "12.893240682248894\n",
      "9.597750076010946\n",
      "3166\n"
     ]
    }
   ],
   "source": [
    "# build dictionary about ocr info\n",
    "# key: image id\n",
    "# value: number of ocr tokens detected\n",
    "train_ocr_info_dict = {train_ocr_data[\"data\"][i][\"image_id\"]:len(train_ocr_data[\"data\"][i][\"ocr_info\"]) for i in range(len(train_ocr_data[\"data\"]))}  # 21953 unique images\n",
    "val_ocr_info_dict = {val_ocr_data[\"data\"][i][\"image_id\"]:len(val_ocr_data[\"data\"][i][\"ocr_info\"]) for i in range(len(val_ocr_data[\"data\"]))}  # 3166 unique images\n",
    "test_ocr_info_dict = {test_ocr_data[\"data\"][i][\"image_id\"]:len(test_ocr_data[\"data\"][i][\"ocr_info\"]) for i in range(len(test_ocr_data[\"data\"]))}  # 3289 unique images\n",
    "\n",
    "# compute average ocr token detected in each dataset\n",
    "print (sum(train_ocr_info_dict.values())/len(train_ocr_data[\"data\"])) # there are on average 12.45 ocr tokens detected per training image \n",
    "print (sum(val_ocr_info_dict.values())/len(val_ocr_data[\"data\"])) # there are on average 12.89 ocr tokens detected per validation image\n",
    "print (sum(test_ocr_info_dict.values())/len(test_ocr_data[\"data\"])) # there are on average 9.60 ocr tokens detected per test image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Detection Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.044321960552089\n",
      "5.3092229943145925\n",
      "9.139799792889196\n"
     ]
    }
   ],
   "source": [
    "# construct dataframes of object detection \n",
    "# columns: image id, count of objects detected\n",
    "train_img_obj_count = train_img_df.groupby([\"ImageID\"]).size().reset_index(name='count')\n",
    "val_img_obj_count = val_img_df.groupby([\"ImageID\"]).size().reset_index(name='count')\n",
    "test_img_obj_count = test_img_df.groupby([\"ImageID\"]).size().reset_index(name='count')\n",
    "total_img_obj_count = pd.concat([train_img_obj_count, val_img_obj_count, test_img_obj_count])\n",
    "\n",
    "train_img_obj_count = total_img_obj_count[total_img_obj_count[\"ImageID\"].isin(train_image_id_set)] # 21953 images with 5.04 object detected on average\n",
    "val_img_obj_count = total_img_obj_count[total_img_obj_count[\"ImageID\"].isin(val_image_id_set)] # 3166 images with 5.31 objects detected on average\n",
    "test_img_obj_count = total_img_obj_count[total_img_obj_count[\"ImageID\"].isin(test_image_id_set)] # 2897 images with 9.14 objects detected on average\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
